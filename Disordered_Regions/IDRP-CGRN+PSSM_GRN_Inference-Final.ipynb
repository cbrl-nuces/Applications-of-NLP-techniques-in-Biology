{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497a5f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 12:45:29.891869: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "from sklearn.metrics import *\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ef1175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    #strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bace669",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_aminoAcids = {0:'A', 1:'C', 2:'E', 3:'D', 4:'G', 5:'F', 6:'I', 7:'H', 8:'K', 9:'M', 10:'L',\n",
    "            11:'N', 12:'Q', 13:'P', 14:'S', 15:'R', 16:'T', 17:'W', 18:'V', 19:'Y', 20:'X'}\n",
    "embedding_keys = {\n",
    "        '<pad>':0,\n",
    "        'A':1,\n",
    "        'C':2,\n",
    "        'D':3,\n",
    "        'E':4,\n",
    "        'F':5,\n",
    "        'G':6,\n",
    "        'H':7,\n",
    "        'I':8,\n",
    "        'K':9,\n",
    "        'L':10,\n",
    "        'M':11,\n",
    "        'N':12,\n",
    "        'P':13,\n",
    "        'Q':14,\n",
    "        'R':15,\n",
    "        'S':16,\n",
    "        'T':17,\n",
    "        'V':18,\n",
    "        'W':19,\n",
    "        'X':20,\n",
    "        'Y':21,\n",
    "        'B':22,\n",
    "        'U':23,\n",
    "        'Z':24,\n",
    "        'O':25,\n",
    "        '<mask>':26}\n",
    "embedding_list = list(embedding_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad27e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonZeroCCE(tf.keras.losses.Loss):\n",
    "    def __init__(self,Weights=[],smoothing = None):\n",
    "        super().__init__()\n",
    "        if smoothing is not None:\n",
    "            self.cce = tf.keras.losses.CategoricalCrossentropy(reduction='none', label_smoothing=smoothing)\n",
    "        else:\n",
    "            self.cce = tf.keras.losses.CategoricalCrossentropy(reduction='none')\n",
    "        self.weights = np.array(Weights)\n",
    "    def call(self, y_true, y_pred):\n",
    "        if len(self.weights)>0:\n",
    "            loss = self.cce(self.weights*y_true,y_pred)\n",
    "        else:\n",
    "            loss = self.cce(y_true,y_pred)\n",
    "        return tf.math.reduce_sum(loss)/((y_true.shape[0]*y_true.shape[1])-float(tf.math.reduce_sum(tf.cast(tf.equal(tf.math.reduce_sum(y_true,-1),0),tf.int32))))\n",
    "\n",
    "def Accuracy(y_true,y_pred):\n",
    "    y_true = y_true.numpy()\n",
    "    y_pred = y_pred.numpy()\n",
    "\n",
    "    m = np.sum(y_true, axis=-1)\n",
    "    y_t = np.argmax(y_true[m==1],axis=-1)\n",
    "    y_p = np.argmax(y_pred[m==1],axis=-1)\n",
    "    return accuracy_score(y_t,y_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1524b5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 1862, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = np.load('./Data/Disordered_Regions_Train_Dataset.npz')\n",
    "X = tmp['sequences']\n",
    "X = np.argmax(X,axis=-1)\n",
    "X_p = tmp['pssms']\n",
    "Y = tmp['regions']\n",
    "X_m = X!=0\n",
    "X_m = X_m.astype(np.int32)\n",
    "X_i = np.repeat(np.arange(1,X.shape[1]+1)[None,:], X.shape[0], axis=0)\n",
    "X_i[X==0] = 0\n",
    "max_len = X.shape[1]\n",
    "\n",
    "train_ids = []\n",
    "with open('./Data/DM3000_id.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        if l[:3] == 'Dis':\n",
    "            k = l.split('|')[1].split()[0]\n",
    "        else:\n",
    "            k = l.split()[0]\n",
    "        train_ids += [k]\n",
    "val_ids = []\n",
    "with open('./Data/DM1229_id.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        if l[:3] == 'Dis':\n",
    "            k = l.split('|')[1].split()[0]\n",
    "        else:\n",
    "            k = l.split()[0]\n",
    "        val_ids += [k]\n",
    "a = tmp['seq_ids']\n",
    "tr_ids_m = [True if i in train_ids else False for i in a]\n",
    "val_ids_m = [True if i in val_ids else False for i in a]\n",
    "len(val_ids),len(train_ids)\n",
    "\n",
    "X1_val = X[val_ids_m][:,1:1863]\n",
    "X4_val = X_m[val_ids_m][:,1:1863]\n",
    "X2_val = X_p[val_ids_m][:,1:1863]\n",
    "X3_val = X_i[val_ids_m][:,1:1863]\n",
    "Y_val = Y[val_ids_m][:,1:1863]\n",
    "X4_val = np.expand_dims(X4_val,-1)\n",
    "X4_val.shape\n",
    "#X1_val[X1_val==23]=0\n",
    "\n",
    "\n",
    "X1 = X[tr_ids_m][:,1:1863]\n",
    "X4 = X_m[tr_ids_m][:,1:1863]\n",
    "X2 = X_p[tr_ids_m][:,1:1863]\n",
    "X3 = X_i[tr_ids_m][:,1:1863]\n",
    "Y = Y[tr_ids_m][:,1:1863]\n",
    "\n",
    "X4 = np.expand_dims(X4,-1)\n",
    "X4.shape\n",
    "\n",
    "tmp = np.load('./Data/Disordered_Regions_Test_Dataset.npz')\n",
    "test_ids = []\n",
    "with open('./Data/SL329_id.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        k = l.split('|')[1].split()[0]\n",
    "        test_ids += [k]\n",
    "te_ids_m = [True if i in test_ids else False for i in tmp['seq_ids']]\n",
    "X1_te = np.argmax(tmp['sequences'],axis=-1)[te_ids_m][:,1:1863]\n",
    "X2_te = tmp['pssms'][te_ids_m][:,1:1863]\n",
    "Y_te = tmp['regions'][te_ids_m][:,1:1863]\n",
    "X_m_te = X1_te!=0\n",
    "X4_te = X_m_te.astype(np.int32)\n",
    "X4_te = np.expand_dims(X4_te,-1)\n",
    "X4_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d78695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 12:46:00.607301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 12:46:00.630441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 12:46:00.631002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 12:46:00.631860: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 12:46:00.632283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 12:46:00.632935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 12:46:00.633428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 12:46:01.173055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 12:46:01.173465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 12:46:01.173812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 12:46:01.174137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10398 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "X1_temp = []\n",
    "for seq in X1:\n",
    "    end = np.where(seq==23)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(seq)\n",
    "    else:\n",
    "        end = end[0]\n",
    "    X1_temp.append([embedding_keys[num_aminoAcids[seq[idx]-1]] for idx in range(0,end)])\n",
    "    X1_temp[-1].extend([0]*(2000-len(X1_temp[-1])))\n",
    "    X1_temp[-1] = np.array(X1_temp[-1])\n",
    "X1_temp = np.array(X1_temp)\n",
    "\n",
    "X1_val_temp = []\n",
    "for seq in X1_val:\n",
    "    end = np.where(seq==23)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(seq)\n",
    "    else:\n",
    "        end = end[0]\n",
    "    X1_val_temp.append([embedding_keys[num_aminoAcids[seq[idx]-1]] for idx in range(0,end)])\n",
    "    X1_val_temp[-1].extend([0]*(2000-len(X1_val_temp[-1])))\n",
    "    X1_val_temp[-1] = np.array(X1_val_temp[-1])\n",
    "X1_val_temp = np.array(X1_val_temp)\n",
    "\n",
    "X1_te_temp = []\n",
    "for seq in X1_te:\n",
    "    end = np.where(seq==23)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(seq)\n",
    "    else:\n",
    "        end = end[0]\n",
    "    X1_te_temp.append([embedding_keys[num_aminoAcids[seq[idx]-1]] for idx in range(0,end)])\n",
    "    X1_te_temp[-1].extend([0]*(2000-len(X1_te_temp[-1])))\n",
    "    X1_te_temp[-1] = np.array(X1_te_temp[-1])\n",
    "X1_te_temp = np.array(X1_te_temp)\n",
    "\n",
    "X1_temp_oneHot = np.array(tf.one_hot(X1_temp,len(embedding_keys))[:,:,1:])\n",
    "X1_val_temp_oneHot = np.array(tf.one_hot(X1_val_temp,len(embedding_keys))[:,:,1:])\n",
    "X1_te_temp_oneHot = np.array(tf.one_hot(X1_te_temp,len(embedding_keys))[:,:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "312b48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embeddingLoader(tfk.utils.Sequence):\n",
    "    def __init__(self,path,pssms, masks,Y_oneHot,batch_size=30,shuffle=True):\n",
    "        self.path = path\n",
    "        self.pssms = pssms\n",
    "        self.masks = masks\n",
    "        self.Y_oneHot = copy.deepcopy(np.array(Y_oneHot))\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.length = len(Y_oneHot)\n",
    "        self.indices = np.arange(0,self.length)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def generate_batches(self):\n",
    "        self.Y_oneHot_ = self.Y_oneHot[self.indices]\n",
    "        self.pssms_ = self.pssms[self.indices]\n",
    "        self.masks_ = self.masks[self.indices]\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        self.generate_batches()\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        token_representations = []\n",
    "        for idx in self.indices[index*self.batch_size:(index+1)*self.batch_size]:\n",
    "            token_representations.append(np.load(self.path+str(idx).zfill(6)+'.npy')[0])\n",
    "        return ([\n",
    "                tf.convert_to_tensor(np.array(token_representations)),\n",
    "                self.masks_[index*self.batch_size:(index+1)*self.batch_size],\n",
    "                self.pssms_[index*self.batch_size:(index+1)*self.batch_size]\n",
    "                ],\n",
    "                self.Y_oneHot_[index*self.batch_size:(index+1)*self.batch_size]\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        if self.length%self.batch_size!=0:\n",
    "            return 1+(self.length//self.batch_size)\n",
    "        return self.length//self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fcf1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_Y = np.zeros((3000, 2000, 2))\n",
    "padded_Y[:Y.shape[0],:Y.shape[1],:Y.shape[2]] = Y\n",
    "\n",
    "padded_Y_val = np.zeros((1229, 2000, 2))\n",
    "padded_Y_val[:Y_val.shape[0],:Y_val.shape[1],:Y_val.shape[2]] = Y_val\n",
    "\n",
    "\n",
    "padded_Y_te = np.zeros((318, 2000, 2))\n",
    "padded_Y_te[:Y_te.shape[0],:Y_te.shape[1],:Y_te.shape[2]] = Y_te\n",
    "\n",
    "padded_X2 = np.zeros((3000, 2000, 20))\n",
    "padded_X2[:X2.shape[0],:X2.shape[1],:X2.shape[2]] = X2\n",
    "\n",
    "padded_X2_val = np.zeros((1229, 2000, 20))\n",
    "padded_X2_val[:X2_val.shape[0],:X2_val.shape[1],:X2_val.shape[2]] = X2_val\n",
    "\n",
    "\n",
    "padded_X2_te = np.zeros((318, 2000, 20))\n",
    "padded_X2_te[:X2_te.shape[0],:X2_te.shape[1],:X2_te.shape[2]] = X2_te\n",
    "\n",
    "padded_X4 = np.zeros((3000, 2000, 1))\n",
    "padded_X4[:X4.shape[0],:X4.shape[1],:X4.shape[2]] = X4\n",
    "\n",
    "padded_X4_val = np.zeros((1229, 2000, 1))\n",
    "padded_X4_val[:X4_val.shape[0],:X4_val.shape[1],:X4_val.shape[2]] = X4_val\n",
    "\n",
    "\n",
    "padded_X4_te = np.zeros((318, 2000, 1))\n",
    "padded_X4_te[:X4_te.shape[0],:X4_te.shape[1],:X4_te.shape[2]] = X4_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2423502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence_input (InputLayer)    [(None, 2000, 300)]  0           []                               \n",
      "                                                                                                  \n",
      " mask (InputLayer)              [(None, 2000, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 2000, 300)    0           ['sequence_input[0][0]',         \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " pssm (InputLayer)              [(None, 2000, 20)]   0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2000, 320)    0           ['multiply[0][0]',               \n",
      "                                                                  'pssm[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru1 (Bidirectional)         (None, 2000, 300)    424800      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 2000, 300)    0           ['bigru1[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru2 (Bidirectional)         (None, 2000, 300)    406800      ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 2000, 300)    0           ['bigru2[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output1 (TimeDistributed)      (None, 2000, 500)    150500      ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 2000, 500)    0           ['output1[0][0]',                \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output2 (TimeDistributed)      (None, 2000, 500)    250500      ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " output (TimeDistributed)       (None, 2000, 2)      1002        ['output2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,233,602\n",
      "Trainable params: 1,233,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    input1_ = tfk.layers.Input(shape=(2000,300, ), name='sequence_input')\n",
    "    input2_ = tfk.layers.Input(shape=(2000,1, ), name='mask')\n",
    "    input3_ = tfk.layers.Input(shape=(2000,20, ), name='pssm')\n",
    "\n",
    "    x = tfk.layers.Multiply()([input1_, input2_])\n",
    "    x = tfk.layers.concatenate([x, input3_], axis=-1)\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru2')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    \n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output2')(x)\n",
    "    output_ = tfk.layers.TimeDistributed(tfk.layers.Dense(2, activation='softmax') ,name='output')(x)\n",
    "    \n",
    "    conv_model = tfk.models.Model([input1_, input2_, input3_], output_)\n",
    "    conv_model.compile(loss=NonZeroCCE(), metrics=[Accuracy], optimizer='adam', run_eagerly = True)\n",
    "    conv_model.summary()\n",
    "conv_model.load_weights(\"./Weights/conv_pssm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a223ce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************Conv ONLY*******************************************\n",
      "\n",
      "\n",
      "*******************************************VALIDATION*******************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 12:48:23.248028: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 42s 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96    276748\n",
      "           1       0.81      0.41      0.55     29082\n",
      "\n",
      "    accuracy                           0.93    305830\n",
      "   macro avg       0.87      0.70      0.76    305830\n",
      "weighted avg       0.93      0.93      0.93    305830\n",
      "\n",
      "[[273837   2911]\n",
      " [ 17031  12051]] 0.9347938397148743\n",
      "0.4143800288838457 0.9894814054663449 0.7019307171750953 0.549216993433059 0.9251527004027899\n",
      "\n",
      "\n",
      "*******************************************Test*******************************************\n",
      "11/11 [==============================] - 10s 980ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86     47388\n",
      "           1       0.91      0.63      0.75     34221\n",
      "\n",
      "    accuracy                           0.82     81609\n",
      "   macro avg       0.85      0.79      0.80     81609\n",
      "weighted avg       0.84      0.82      0.81     81609\n",
      "\n",
      "[[45328  2060]\n",
      " [12572 21649]] 0.8207060495778652\n",
      "0.6326232430379007 0.9565290790917532 0.794576161064827 0.6403423590302395 0.8133890683411231\n"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************Conv ONLY*******************************************\")\n",
    "print()\n",
    "print()\n",
    "val_loader = embeddingLoader(\"./Data/Embeddings/Conv/val/\",padded_X2_val,padded_X4_val,padded_Y_val,30,False)\n",
    "print(\"*******************************************VALIDATION*******************************************\")\n",
    "preds = conv_model.predict(val_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_val, axis=-1)\n",
    "y_t = np.argmax(padded_Y_val[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n",
    "\n",
    "test_loader = embeddingLoader(\"./Data/Embeddings/Conv/test/\",padded_X2_te, padded_X4_te,padded_Y_te,30,False)\n",
    "print()\n",
    "print()\n",
    "print(\"*******************************************Test*******************************************\")\n",
    "preds = conv_model.predict(test_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_te, axis=-1)\n",
    "y_t = np.argmax(padded_Y_te[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbbecb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence_input (InputLayer)    [(None, 2000, 300)]  0           []                               \n",
      "                                                                                                  \n",
      " mask (InputLayer)              [(None, 2000, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 2000, 300)    0           ['sequence_input[0][0]',         \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " pssm (InputLayer)              [(None, 2000, 20)]   0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2000, 320)    0           ['multiply_4[0][0]',             \n",
      "                                                                  'pssm[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru1 (Bidirectional)         (None, 2000, 300)    424800      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 2000, 300)    0           ['bigru1[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru2 (Bidirectional)         (None, 2000, 300)    406800      ['multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 2000, 300)    0           ['bigru2[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output1 (TimeDistributed)      (None, 2000, 500)    150500      ['multiply_6[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 2000, 500)    0           ['output1[0][0]',                \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output2 (TimeDistributed)      (None, 2000, 500)    250500      ['multiply_7[0][0]']             \n",
      "                                                                                                  \n",
      " output (TimeDistributed)       (None, 2000, 2)      1002        ['output2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,233,602\n",
      "Trainable params: 1,233,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    input1_ = tfk.layers.Input(shape=(2000,300, ), name='sequence_input')\n",
    "    input2_ = tfk.layers.Input(shape=(2000,1, ), name='mask')\n",
    "    input3_ = tfk.layers.Input(shape=(2000,20, ), name='pssm')\n",
    "    \n",
    "    x = tfk.layers.Multiply()([input1_, input2_])\n",
    "    x = tfk.layers.concatenate([x, input3_], axis=-1)\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru2')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])    \n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output2')(x)\n",
    "    output_ = tfk.layers.TimeDistributed(tfk.layers.Dense(2, activation='softmax') ,name='output')(x)\n",
    "    \n",
    "    gru_model = tfk.models.Model([input1_, input2_, input3_], output_)\n",
    "    gru_model.compile(loss=NonZeroCCE(), metrics=[Accuracy], optimizer='adam', run_eagerly = True)\n",
    "    gru_model.summary()\n",
    "gru_model.load_weights(\"./Weights/gru_pssm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f33fd34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************GRU ONLY*******************************************\n",
      "\n",
      "\n",
      "*******************************************VALIDATION*******************************************\n",
      "41/41 [==============================] - 43s 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96    276748\n",
      "           1       0.74      0.50      0.59     29082\n",
      "\n",
      "    accuracy                           0.94    305830\n",
      "   macro avg       0.84      0.74      0.78    305830\n",
      "weighted avg       0.93      0.94      0.93    305830\n",
      "\n",
      "[[271583   5165]\n",
      " [ 14616  14466]] 0.9353202759703103\n",
      "0.49742108520734474 0.9813368118288117 0.7393789485180782 0.5730137767904264 0.9295888283469718\n",
      "\n",
      "\n",
      "*******************************************Test*******************************************\n",
      "11/11 [==============================] - 10s 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87     47388\n",
      "           1       0.88      0.71      0.79     34221\n",
      "\n",
      "    accuracy                           0.84     81609\n",
      "   macro avg       0.85      0.82      0.83     81609\n",
      "weighted avg       0.85      0.84      0.84     81609\n",
      "\n",
      "[[44195  3193]\n",
      " [ 9761 24460]] 0.8412675072602287\n",
      "0.7147657870897987 0.9326200725922175 0.8236929298410081 0.6749206986987979 0.8379863286130365\n"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************GRU ONLY*******************************************\")\n",
    "print()\n",
    "print()\n",
    "val_loader = embeddingLoader(\"./Data/Embeddings/GRU/val/\",padded_X2_val,padded_X4_val,padded_Y_val,30,False)\n",
    "print(\"*******************************************VALIDATION*******************************************\")\n",
    "preds = gru_model.predict(val_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_val, axis=-1)\n",
    "y_t = np.argmax(padded_Y_val[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n",
    "\n",
    "test_loader = embeddingLoader(\"./Data/Embeddings/GRU/test/\",padded_X2_te, padded_X4_te,padded_Y_te,30,False)\n",
    "print()\n",
    "print()\n",
    "print(\"*******************************************Test*******************************************\")\n",
    "preds = gru_model.predict(test_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_te, axis=-1)\n",
    "y_t = np.argmax(padded_Y_te[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a27be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence_input (InputLayer)    [(None, 2000, 600)]  0           []                               \n",
      "                                                                                                  \n",
      " mask (InputLayer)              [(None, 2000, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)          (None, 2000, 600)    0           ['sequence_input[0][0]',         \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " pssm (InputLayer)              [(None, 2000, 20)]   0           []                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 2000, 620)    0           ['multiply_8[0][0]',             \n",
      "                                                                  'pssm[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru1 (Bidirectional)         (None, 2000, 300)    694800      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_9 (Multiply)          (None, 2000, 300)    0           ['bigru1[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru2 (Bidirectional)         (None, 2000, 300)    406800      ['multiply_9[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_10 (Multiply)         (None, 2000, 300)    0           ['bigru2[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output1 (TimeDistributed)      (None, 2000, 500)    150500      ['multiply_10[0][0]']            \n",
      "                                                                                                  \n",
      " multiply_11 (Multiply)         (None, 2000, 500)    0           ['output1[0][0]',                \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output2 (TimeDistributed)      (None, 2000, 500)    250500      ['multiply_11[0][0]']            \n",
      "                                                                                                  \n",
      " output (TimeDistributed)       (None, 2000, 2)      1002        ['output2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,503,602\n",
      "Trainable params: 1,503,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    input1_ = tfk.layers.Input(shape=(2000,600, ), name='sequence_input')\n",
    "    input2_ = tfk.layers.Input(shape=(2000,1, ), name='mask')\n",
    "    input3_ = tfk.layers.Input(shape=(2000,20, ), name='pssm')\n",
    "    \n",
    "    x = tfk.layers.Multiply()([input1_, input2_])\n",
    "    x = tfk.layers.concatenate([x, input3_], axis=-1)\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru2')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])    \n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output2')(x)\n",
    "    output_ = tfk.layers.TimeDistributed(tfk.layers.Dense(2, activation='softmax') ,name='output')(x)\n",
    "    \n",
    "    conv_GRU_model = tfk.models.Model([input1_, input2_, input3_], output_)\n",
    "    conv_GRU_model.compile(loss=NonZeroCCE(), metrics=[Accuracy], optimizer='adam', run_eagerly = True)\n",
    "    conv_GRU_model.summary()\n",
    "conv_GRU_model.load_weights(\"./Weights/conv_gru_pssm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d4fc97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************Conv_GRU ONLY*******************************************\n",
      "\n",
      "\n",
      "*******************************************VALIDATION*******************************************\n",
      "41/41 [==============================] - 83s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96    276748\n",
      "           1       0.80      0.42      0.55     29082\n",
      "\n",
      "    accuracy                           0.93    305830\n",
      "   macro avg       0.87      0.71      0.76    305830\n",
      "weighted avg       0.93      0.93      0.93    305830\n",
      "\n",
      "[[273667   3081]\n",
      " [ 16804  12278]] 0.9349802177680411\n",
      "0.4221855443229489 0.9888671282177288 0.7055263362703389 0.552101588424858 0.9257279692704664\n",
      "\n",
      "\n",
      "*******************************************Test*******************************************\n",
      "11/11 [==============================] - 21s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87     47388\n",
      "           1       0.91      0.67      0.77     34221\n",
      "\n",
      "    accuracy                           0.84     81609\n",
      "   macro avg       0.86      0.81      0.82     81609\n",
      "weighted avg       0.85      0.84      0.83     81609\n",
      "\n",
      "[[45223  2165]\n",
      " [11280 22941]] 0.8352510139813011\n",
      "0.670377838169545 0.95431332826876 0.8123455832191525 0.6679152923086291 0.8298222210253716\n"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************Conv_GRU ONLY*******************************************\")\n",
    "print()\n",
    "print()\n",
    "val_loader = embeddingLoader(\"./Data/Embeddings/Conv_GRU/val/\",padded_X2_val,padded_X4_val,padded_Y_val,30,False)\n",
    "print(\"*******************************************VALIDATION*******************************************\")\n",
    "preds = conv_GRU_model.predict(val_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_val, axis=-1)\n",
    "y_t = np.argmax(padded_Y_val[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n",
    "\n",
    "test_loader = embeddingLoader(\"./Data/Embeddings/Conv_GRU/test/\",padded_X2_te, padded_X4_te,padded_Y_te,30,False)\n",
    "print()\n",
    "print()\n",
    "print(\"*******************************************Test*******************************************\")\n",
    "preds = conv_GRU_model.predict(test_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_te, axis=-1)\n",
    "y_t = np.argmax(padded_Y_te[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406db89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
