{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataPath = 'Data/Disordered_Regions_Train_Dataset.npz'\n",
    "testDataPath = 'Data/Disordered_Regions_Test_Dataset.npz'\n",
    "\n",
    "residues = {'A':1, 'C':2, 'E':3, 'D':4, 'G':5, 'F':6, 'I':7, 'H':8, 'K':9, \n",
    "            'M':10, 'L':11, 'N':12, 'Q':13, 'P':14, 'S':15, 'R':16, 'T':17, \n",
    "            'W':18, 'V':19, 'Y':20, 'X':21, '<SOS>':22, '<EOS>':23}\n",
    "residues_i = {j:i for i,j in residues.items()}\n",
    "\n",
    "tmp = np.load('Data/Secondary_Structure_Motif_Antimotif.npz')\n",
    "motifs = tmp['motifs']\n",
    "antimotifs = tmp['antimotifs']\n",
    "len(motifs),len(antimotifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRowData(seq_, pssm, winSize):\n",
    "    seq_ = np.argmax(seq_, axis=-1)\n",
    "    winApp = winSize // 2\n",
    "    max_len = seq_.shape[0]\n",
    "    \n",
    "    input1 = np.zeros((max_len, winSize))\n",
    "    input2 = np.zeros((max_len, winSize, 20))\n",
    "    input3 = np.zeros((max_len, winSize, len(motifs)))\n",
    "    input4 = np.zeros((max_len, winSize, len(antimotifs)))\n",
    "    input5 = np.zeros((max_len, winSize))\n",
    "    input6 = np.zeros((max_len, 1))\n",
    "    \n",
    "    seq = '-' * winApp\n",
    "    seq += 'O'\n",
    "    input6[0,0] = 1\n",
    "    input5[0,:] = 1\n",
    "    for j in range(1,seq_.shape[0]):\n",
    "        if seq_[j] == 23:\n",
    "            break\n",
    "        seq += residues_i[seq_[j]]\n",
    "        input6[j,0] = 1\n",
    "        input5[j,:] = j+1\n",
    "    input6[j,0] = 1\n",
    "    input5[j,:] = j+1\n",
    "    seq += 'J'\n",
    "    seq += '-'*winApp\n",
    "    for _ in range(winApp):\n",
    "        pssm = np.append([np.zeros((20,))], pssm, axis=0)\n",
    "        pssm = np.append(pssm, [np.zeros((20,))], axis=0)\n",
    "    for j in range(len(seq) - winSize + 1):\n",
    "        a = seq[j : j + winSize]\n",
    "        c = pssm[j : j + winSize]\n",
    "        for t in range(winSize):\n",
    "            if a[t] == 'O':\n",
    "                input1[j, t] = residues['<SOS>']\n",
    "            elif a[t] == 'J':\n",
    "                input1[j, t] = residues['<EOS>']\n",
    "            elif a[t] != '-':\n",
    "                input1[j, t] = residues[a[t]]\n",
    "            input2[j, t] = c[t]\n",
    "            for p,m in enumerate(motifs):\n",
    "                k_ = int(m[3])\n",
    "                if winSize-t > k_:\n",
    "                    if a[t] == m[0] and a[t+k_] == m[1]:\n",
    "                        input3[j, t:t+k_+1, p] += 1.\n",
    "            for p,m in enumerate(antimotifs):\n",
    "                k_ = int(m[3])\n",
    "                if winSize-t > k_:\n",
    "                    if a[t] == m[0] and a[t+k_] == m[1]:\n",
    "                        input4[j, t:t+k_+1, p] += 1.\n",
    "    return input1, input2, input5, input3, input4, input6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataGenerator(tfk.utils.Sequence):\n",
    "    def __init__(self, file_path, batch_size=4, win_size=11, seq_len=1864, valData=0):\n",
    "        self.__getData__(file_path)\n",
    "        self.__seq_len__ = seq_len\n",
    "        self.__win_size__ = win_size\n",
    "        self.__batch_size__ = batch_size\n",
    "        self.__valData__ = valData\n",
    "        if self.__valData__ == 0:\n",
    "            train_ids = []\n",
    "            with open('Data/DM3000_id.txt') as f:\n",
    "                for l in f.readlines():\n",
    "                    if l[:3] == 'Dis':\n",
    "                        k = l.split('|')[1].split()[0]\n",
    "                    else:\n",
    "                        k = l.split()[0]\n",
    "                    train_ids += [k]\n",
    "            self.__indexes__ = [k for k,i in enumerate(self.__a_id__) if i in train_ids]\n",
    "            self.__n_examples__ = len(self.__indexes__)\n",
    "        elif self.__valData__ == 1:\n",
    "            val_ids = []\n",
    "            with open('Data/DM1229_id.txt') as f:\n",
    "                for l in f.readlines():\n",
    "                    if l[:3] == 'Dis':\n",
    "                        k = l.split('|')[1].split()[0]\n",
    "                    else:\n",
    "                        k = l.split()[0]\n",
    "                    val_ids += [k]\n",
    "            self.__indexes__ = [k for k,i in enumerate(self.__a_id__) if i in val_ids]\n",
    "            self.__n_examples__ = len(self.__indexes__)\n",
    "        else:\n",
    "            test_ids = []\n",
    "            with open('Data/SL329_id.txt') as f:\n",
    "                for l in f.readlines():\n",
    "                    k = l.split('|')[1].split()[0]\n",
    "                    test_ids += [k]\n",
    "            self.__indexes__ = [k for k,i in enumerate(self.__a_id__) if i in test_ids]\n",
    "            self.__n_examples__ = len(self.__indexes__)\n",
    "        np.random.seed(42)\n",
    "    def __len__(self):\n",
    "        return self.__n_examples__ // self.__batch_size__\n",
    "    def __getData__(self, file_path):\n",
    "        data = np.load(file_path)\n",
    "        self.__sequences__ = data['sequences']\n",
    "        self.__pssms__ = data['pssms']\n",
    "        self.__labels__ = data['regions']\n",
    "        self.__a_id__ = data['seq_ids']\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.__indexes__[index*self.__batch_size__:(index+1)*self.__batch_size__]\n",
    "        X1, X2, X3, X4, X5, X6, y = self.__data_generation(indexes)\n",
    "        return [X1, X2, X3, X4, X5, X6], y\n",
    "    def __data_generation(self, indexes):\n",
    "        x1 = np.empty((self.__batch_size__, self.__seq_len__, self.__win_size__))\n",
    "        x2 = np.empty((self.__batch_size__, self.__seq_len__, self.__win_size__, 20))\n",
    "        x3 = np.empty((self.__batch_size__, self.__seq_len__, self.__win_size__))\n",
    "        x4 = np.empty((self.__batch_size__, self.__seq_len__, self.__win_size__, len(motifs)))\n",
    "        x5 = np.empty((self.__batch_size__, self.__seq_len__, self.__win_size__, len(antimotifs)))\n",
    "        x6 = np.empty((self.__batch_size__, self.__seq_len__, 1))\n",
    "        y = np.empty((self.__batch_size__, self.__seq_len__, 2))\n",
    "        for k in range(len(indexes)):\n",
    "            ind = indexes[k]\n",
    "            i1,i2,i3,i4,i5,i6 = getRowData(self.__sequences__[ind],self.__pssms__[ind],self.__win_size__)\n",
    "            x1[k,] = i1\n",
    "            x2[k,] = i2\n",
    "            x3[k,] = i3\n",
    "            x4[k,] = i4\n",
    "            x5[k,] = i5\n",
    "            x6[k,] = i6\n",
    "            y[k,] = self.__labels__[ind]\n",
    "        return x1, x2, x3, x4, x5, x6, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_list(x):\n",
    "    tmp = list(K.int_shape(x))\n",
    "    tmp[0] = -1\n",
    "    return tmp\n",
    "\n",
    "def selfAttention(V, mask):\n",
    "    units = int(V.shape[2])\n",
    "    Q = tfk.layers.TimeDistributed( tfk.layers.Dense(units, activation=None, use_bias=False))(V)\n",
    "    K_ = tfk.layers.TimeDistributed( tfk.layers.Dense(units, activation=None, use_bias=False))(Q)\n",
    "    SoftAtten = tfk.layers.Dot(axes=-1, normalize=False)([Q, K_])\n",
    "    SoftAtten = tfk.layers.Lambda(lambda inp: inp[0]/K.sqrt(K.cast(shape_list(inp[1])[-1], K.floatx())))([SoftAtten, V])\n",
    "    SoftAtten = tfk.layers.Softmax(axis=-1)(SoftAtten)\n",
    "    SoftAtten = tfk.layers.Multiply()([SoftAtten, mask])\n",
    "    V = tfk.layers.Permute([2,1])(V)\n",
    "    SA = tfk.layers.Dot(axes=-1, normalize=False)([SoftAtten, V])\n",
    "    return SA,SoftAtten\n",
    "\n",
    "def _getPosEncodingMat(length, dim):\n",
    "    posEnc = np.array([[pos/np.power(10000, 2*(j//2)/dim) for j in range(dim)]\n",
    "                        if pos!=0 else np.zeros(dim) for pos in range(length)], dtype=np.float32)\n",
    "    posEnc[1:, 0::2] = np.sin(posEnc[1:, 0::2])\n",
    "    posEnc[1:, 1::2] = np.cos(posEnc[1:, 1::2])\n",
    "    return posEnc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    input1 = tfk.layers.Input(shape=(1864,11 ), name='sequence_input')\n",
    "    input2 = tfk.layers.Input(shape=(1864,11,20, ), name='pssm_input')\n",
    "    input3 = tfk.layers.Input(shape=(1864,11, ), name='pids_input')\n",
    "    input4 = tfk.layers.Input(shape=(1864,11,len(motifs), ), name='motif_input')\n",
    "    input5 = tfk.layers.Input(shape=(1864,11,len(antimotifs), ), name='antimotif_input')\n",
    "    input6 = tfk.layers.Input(shape=(1864,1, ), name='mask_input')\n",
    "    \n",
    "    pidsEmbd = tfk.layers.Embedding(input_dim=1864, output_dim=100, trainable=False,\n",
    "                                  weights=[_getPosEncodingMat(1864, 100)], name='pids_embds')(input3)\n",
    "    emb = tfk.layers.Embedding(input_dim=24, output_dim=100, name='embds')(input1)\n",
    "    seq_embd = tfk.layers.Add(name='seq_embdAdd')([emb, pidsEmbd])\n",
    "    \n",
    "    x1 = tfk.layers.TimeDistributed(tfk.layers.Conv1D(100, 11, strides=1, padding='same', activation='relu'), name='conv1')(seq_embd)\n",
    "    x1 = tfk.layers.TimeDistributed(tfk.layers.GlobalMaxPooling1D())(x1)\n",
    "    x2 = tfk.layers.concatenate([input2, input4, input5], axis=-1, name='con1')\n",
    "    x2 = tfk.layers.TimeDistributed(tfk.layers.Conv1D(100, 11, strides=1, padding='same', activation='relu'), name='conv2')(x2)\n",
    "    x2 = tfk.layers.TimeDistributed(tfk.layers.GlobalMaxPooling1D())(x2)\n",
    "\n",
    "    x1 = tfk.layers.LSTM(units=100, return_sequences=True, name='lstm1')(x1)\n",
    "    model = tfk.layers.concatenate([x1, x2], axis=-1, name='con2')\n",
    "    \n",
    "    model,_ = selfAttention(model, input6)\n",
    "    \n",
    "    model = tfk.layers.Bidirectional( tfk.layers.LSTM(units=200, return_sequences=True), name='lstm2')(model)\n",
    "\n",
    "    model = tfk.layers.TimeDistributed( tfk.layers.Dense(200, activation='relu'), name='output1')(model)\n",
    "    model = tfk.layers.TimeDistributed( tfk.layers.Dense(200, activation='relu'), name='output2')(model)\n",
    "    output = tfk.layers.TimeDistributed( tfk.layers.Dense(2, activation='softmax') ,name='output')(model)\n",
    "\n",
    "    model = tfk.models.Model([input1, input2, input3, input4, input5, input6], output)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = dataGenerator(trainDataPath, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(train_gen, verbose=1, epochs=50)\n",
    "# model.save_weights('Weights/WB-ALSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('Weights/WB-ALSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = dataGenerator(trainDataPath, batch_size=1, valData=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = None\n",
    "preds = None\n",
    "for i in tqdm(range(val_gen.__len__()), total=val_gen.__len__()):\n",
    "    inputs, outputs = val_gen.__getitem__(i)\n",
    "    preds_ = model.predict(inputs)\n",
    "    if trues is None:\n",
    "        trues = outputs\n",
    "        preds = preds_\n",
    "    else:\n",
    "        trues = np.append(trues, outputs, axis=0)\n",
    "        preds = np.append(preds, preds_, axis=0)\n",
    "np.savez_compressed('wb-alstm-vals', val_tr=trues, val_pr=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.sum(trues, axis=-1)\n",
    "y_t = np.argmax(trues[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[1][0],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[0][1],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "sp,sn,bacc,mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = dataGenerator(testDataPath, batch_size=1, valData=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = None\n",
    "preds = None\n",
    "for i in tqdm(range(test_gen.__len__()), total=test_gen.__len__()):\n",
    "    inputs, outputs = test_gen.__getitem__(i)\n",
    "    preds_ = model.predict(inputs)\n",
    "    if trues is None:\n",
    "        trues = outputs\n",
    "        preds = preds_\n",
    "    else:\n",
    "        trues = np.append(trues, outputs, axis=0)\n",
    "        preds = np.append(preds, preds_, axis=0)\n",
    "np.savez_compressed('wb-alstm-test', te_tr=trues, te_pr=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.sum(trues, axis=-1)\n",
    "y_t = np.argmax(trues[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[1][0],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[0][1],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
