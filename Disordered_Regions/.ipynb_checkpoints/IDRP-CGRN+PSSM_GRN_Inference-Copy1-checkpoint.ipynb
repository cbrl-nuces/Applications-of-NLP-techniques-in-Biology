{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497a5f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 00:45:49.907375: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "from sklearn.metrics import *\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ef1175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    #strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bace669",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_aminoAcids = {0:'A', 1:'C', 2:'E', 3:'D', 4:'G', 5:'F', 6:'I', 7:'H', 8:'K', 9:'M', 10:'L',\n",
    "            11:'N', 12:'Q', 13:'P', 14:'S', 15:'R', 16:'T', 17:'W', 18:'V', 19:'Y', 20:'X'}\n",
    "embedding_keys = {\n",
    "        '<pad>':0,\n",
    "        'A':1,\n",
    "        'C':2,\n",
    "        'D':3,\n",
    "        'E':4,\n",
    "        'F':5,\n",
    "        'G':6,\n",
    "        'H':7,\n",
    "        'I':8,\n",
    "        'K':9,\n",
    "        'L':10,\n",
    "        'M':11,\n",
    "        'N':12,\n",
    "        'P':13,\n",
    "        'Q':14,\n",
    "        'R':15,\n",
    "        'S':16,\n",
    "        'T':17,\n",
    "        'V':18,\n",
    "        'W':19,\n",
    "        'X':20,\n",
    "        'Y':21,\n",
    "        'B':22,\n",
    "        'U':23,\n",
    "        'Z':24,\n",
    "        'O':25,\n",
    "        '<mask>':26}\n",
    "embedding_list = list(embedding_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad27e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonZeroCCE(tf.keras.losses.Loss):\n",
    "    def __init__(self,Weights=[],smoothing = None):\n",
    "        super().__init__()\n",
    "        if smoothing is not None:\n",
    "            self.cce = tf.keras.losses.CategoricalCrossentropy(reduction='none', label_smoothing=smoothing)\n",
    "        else:\n",
    "            self.cce = tf.keras.losses.CategoricalCrossentropy(reduction='none')\n",
    "        self.weights = np.array(Weights)\n",
    "    def call(self, y_true, y_pred):\n",
    "        if len(self.weights)>0:\n",
    "            loss = self.cce(self.weights*y_true,y_pred)\n",
    "        else:\n",
    "            loss = self.cce(y_true,y_pred)\n",
    "        return tf.math.reduce_sum(loss)/((y_true.shape[0]*y_true.shape[1])-float(tf.math.reduce_sum(tf.cast(tf.equal(tf.math.reduce_sum(y_true,-1),0),tf.int32))))\n",
    "\n",
    "def Accuracy(y_true,y_pred):\n",
    "    y_true = y_true.numpy()\n",
    "    y_pred = y_pred.numpy()\n",
    "\n",
    "    m = np.sum(y_true, axis=-1)\n",
    "    y_t = np.argmax(y_true[m==1],axis=-1)\n",
    "    y_p = np.argmax(y_pred[m==1],axis=-1)\n",
    "    return accuracy_score(y_t,y_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1524b5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 1862, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = np.load('./Data/Disordered_Regions_Train_Dataset.npz')\n",
    "X = tmp['sequences']\n",
    "X = np.argmax(X,axis=-1)\n",
    "X_p = tmp['pssms']\n",
    "Y = tmp['regions']\n",
    "X_m = X!=0\n",
    "X_m = X_m.astype(np.int32)\n",
    "X_i = np.repeat(np.arange(1,X.shape[1]+1)[None,:], X.shape[0], axis=0)\n",
    "X_i[X==0] = 0\n",
    "max_len = X.shape[1]\n",
    "\n",
    "train_ids = []\n",
    "with open('./Data/DM3000_id.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        if l[:3] == 'Dis':\n",
    "            k = l.split('|')[1].split()[0]\n",
    "        else:\n",
    "            k = l.split()[0]\n",
    "        train_ids += [k]\n",
    "val_ids = []\n",
    "with open('./Data/DM1229_id.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        if l[:3] == 'Dis':\n",
    "            k = l.split('|')[1].split()[0]\n",
    "        else:\n",
    "            k = l.split()[0]\n",
    "        val_ids += [k]\n",
    "a = tmp['seq_ids']\n",
    "tr_ids_m = [True if i in train_ids else False for i in a]\n",
    "val_ids_m = [True if i in val_ids else False for i in a]\n",
    "len(val_ids),len(train_ids)\n",
    "\n",
    "X1_val = X[val_ids_m][:,1:1863]\n",
    "X4_val = X_m[val_ids_m][:,1:1863]\n",
    "X2_val = X_p[val_ids_m][:,1:1863]\n",
    "X3_val = X_i[val_ids_m][:,1:1863]\n",
    "Y_val = Y[val_ids_m][:,1:1863]\n",
    "X4_val = np.expand_dims(X4_val,-1)\n",
    "X4_val.shape\n",
    "#X1_val[X1_val==23]=0\n",
    "\n",
    "\n",
    "X1 = X[tr_ids_m][:,1:1863]\n",
    "X4 = X_m[tr_ids_m][:,1:1863]\n",
    "X2 = X_p[tr_ids_m][:,1:1863]\n",
    "X3 = X_i[tr_ids_m][:,1:1863]\n",
    "Y = Y[tr_ids_m][:,1:1863]\n",
    "\n",
    "X4 = np.expand_dims(X4,-1)\n",
    "X4.shape\n",
    "\n",
    "tmp = np.load('./Data/Disordered_Regions_Test_Dataset.npz')\n",
    "test_ids = []\n",
    "with open('./Data/SL329_id.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        k = l.split('|')[1].split()[0]\n",
    "        test_ids += [k]\n",
    "te_ids_m = [True if i in test_ids else False for i in tmp['seq_ids']]\n",
    "X1_te = np.argmax(tmp['sequences'],axis=-1)[te_ids_m][:,1:1863]\n",
    "X2_te = tmp['pssms'][te_ids_m][:,1:1863]\n",
    "Y_te = tmp['regions'][te_ids_m][:,1:1863]\n",
    "X_m_te = X1_te!=0\n",
    "X4_te = X_m_te.astype(np.int32)\n",
    "X4_te = np.expand_dims(X4_te,-1)\n",
    "X4_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d78695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 00:46:52.434367: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-04-30 00:46:52.434388: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: cbrls0\n",
      "2023-04-30 00:46:52.434392: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: cbrls0\n",
      "2023-04-30 00:46:52.434441: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.182.3\n",
      "2023-04-30 00:46:52.434452: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.182.3\n",
      "2023-04-30 00:46:52.434456: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.182.3\n",
      "2023-04-30 00:46:52.434582: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 00:46:52.459724: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 648000000 exceeds 10% of free system memory.\n",
      "2023-04-30 00:46:52.527936: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 624000000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "X1_temp = []\n",
    "for seq in X1:\n",
    "    end = np.where(seq==23)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(seq)\n",
    "    else:\n",
    "        end = end[0]\n",
    "    X1_temp.append([embedding_keys[num_aminoAcids[seq[idx]-1]] for idx in range(0,end)])\n",
    "    X1_temp[-1].extend([0]*(2000-len(X1_temp[-1])))\n",
    "    X1_temp[-1] = np.array(X1_temp[-1])\n",
    "X1_temp = np.array(X1_temp)\n",
    "\n",
    "X1_val_temp = []\n",
    "for seq in X1_val:\n",
    "    end = np.where(seq==23)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(seq)\n",
    "    else:\n",
    "        end = end[0]\n",
    "    X1_val_temp.append([embedding_keys[num_aminoAcids[seq[idx]-1]] for idx in range(0,end)])\n",
    "    X1_val_temp[-1].extend([0]*(2000-len(X1_val_temp[-1])))\n",
    "    X1_val_temp[-1] = np.array(X1_val_temp[-1])\n",
    "X1_val_temp = np.array(X1_val_temp)\n",
    "\n",
    "X1_te_temp = []\n",
    "for seq in X1_te:\n",
    "    end = np.where(seq==23)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(seq)\n",
    "    else:\n",
    "        end = end[0]\n",
    "    X1_te_temp.append([embedding_keys[num_aminoAcids[seq[idx]-1]] for idx in range(0,end)])\n",
    "    X1_te_temp[-1].extend([0]*(2000-len(X1_te_temp[-1])))\n",
    "    X1_te_temp[-1] = np.array(X1_te_temp[-1])\n",
    "X1_te_temp = np.array(X1_te_temp)\n",
    "\n",
    "X1_temp_oneHot = np.array(tf.one_hot(X1_temp,len(embedding_keys))[:,:,1:])\n",
    "X1_val_temp_oneHot = np.array(tf.one_hot(X1_val_temp,len(embedding_keys))[:,:,1:])\n",
    "X1_te_temp_oneHot = np.array(tf.one_hot(X1_te_temp,len(embedding_keys))[:,:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "312b48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embeddingLoader(tfk.utils.Sequence):\n",
    "    def __init__(self,path,pssms, masks,Y_oneHot,batch_size=30,shuffle=True):\n",
    "        self.path = path\n",
    "        self.pssms = pssms\n",
    "        self.masks = masks\n",
    "        self.Y_oneHot = copy.deepcopy(np.array(Y_oneHot))\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.length = len(Y_oneHot)\n",
    "        self.indices = np.arange(0,self.length)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def generate_batches(self):\n",
    "        self.Y_oneHot_ = self.Y_oneHot[self.indices]\n",
    "        self.pssms_ = self.pssms[self.indices]\n",
    "        self.masks_ = self.masks[self.indices]\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        self.generate_batches()\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        token_representations = []\n",
    "        for idx in self.indices[index*self.batch_size:(index+1)*self.batch_size]:\n",
    "            token_representations.append(np.load(self.path+str(idx).zfill(6)+'.npy')[0])\n",
    "        return ([\n",
    "                tf.convert_to_tensor(np.array(token_representations)),\n",
    "                self.masks_[index*self.batch_size:(index+1)*self.batch_size],\n",
    "                self.pssms_[index*self.batch_size:(index+1)*self.batch_size]\n",
    "                ],\n",
    "                self.Y_oneHot_[index*self.batch_size:(index+1)*self.batch_size]\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        if self.length%self.batch_size!=0:\n",
    "            return 1+(self.length//self.batch_size)\n",
    "        return self.length//self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fcf1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_Y = np.zeros((3000, 2000, 2))\n",
    "padded_Y[:Y.shape[0],:Y.shape[1],:Y.shape[2]] = Y\n",
    "\n",
    "padded_Y_val = np.zeros((1229, 2000, 2))\n",
    "padded_Y_val[:Y_val.shape[0],:Y_val.shape[1],:Y_val.shape[2]] = Y_val\n",
    "\n",
    "\n",
    "padded_Y_te = np.zeros((318, 2000, 2))\n",
    "padded_Y_te[:Y_te.shape[0],:Y_te.shape[1],:Y_te.shape[2]] = Y_te\n",
    "\n",
    "padded_X2 = np.zeros((3000, 2000, 20))\n",
    "padded_X2[:X2.shape[0],:X2.shape[1],:X2.shape[2]] = X2\n",
    "\n",
    "padded_X2_val = np.zeros((1229, 2000, 20))\n",
    "padded_X2_val[:X2_val.shape[0],:X2_val.shape[1],:X2_val.shape[2]] = X2_val\n",
    "\n",
    "\n",
    "padded_X2_te = np.zeros((318, 2000, 20))\n",
    "padded_X2_te[:X2_te.shape[0],:X2_te.shape[1],:X2_te.shape[2]] = X2_te\n",
    "\n",
    "padded_X4 = np.zeros((3000, 2000, 1))\n",
    "padded_X4[:X4.shape[0],:X4.shape[1],:X4.shape[2]] = X4\n",
    "\n",
    "padded_X4_val = np.zeros((1229, 2000, 1))\n",
    "padded_X4_val[:X4_val.shape[0],:X4_val.shape[1],:X4_val.shape[2]] = X4_val\n",
    "\n",
    "\n",
    "padded_X4_te = np.zeros((318, 2000, 1))\n",
    "padded_X4_te[:X4_te.shape[0],:X4_te.shape[1],:X4_te.shape[2]] = X4_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2423502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " pssm (InputLayer)              [(None, 2000, 20)]   0           []                               \n",
      "                                                                                                  \n",
      " mask (InputLayer)              [(None, 2000, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 2000, 20)     0           ['pssm[0][0]',                   \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " sequence_input (InputLayer)    [(None, 2000, 300)]  0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2000, 320)    0           ['multiply[0][0]',               \n",
      "                                                                  'sequence_input[0][0]']         \n",
      "                                                                                                  \n",
      " bigru1 (Bidirectional)         (None, 2000, 300)    424800      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 2000, 300)    0           ['bigru1[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru2 (Bidirectional)         (None, 2000, 300)    406800      ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 2000, 300)    0           ['bigru2[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output1 (TimeDistributed)      (None, 2000, 500)    150500      ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 2000, 500)    0           ['output1[0][0]',                \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output2 (TimeDistributed)      (None, 2000, 500)    250500      ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " output (TimeDistributed)       (None, 2000, 2)      1002        ['output2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,233,602\n",
      "Trainable params: 1,233,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    input1_ = tfk.layers.Input(shape=(2000,300, ), name='sequence_input')\n",
    "    input2_ = tfk.layers.Input(shape=(2000,1, ), name='mask')\n",
    "    input3_ = tfk.layers.Input(shape=(2000,20, ), name='pssm')\n",
    "\n",
    "    x = tfk.layers.Multiply()([input3_, input2_])\n",
    "    x = tfk.layers.concatenate([x, input1_], axis=-1)\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru2')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    \n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output2')(x)\n",
    "    output_ = tfk.layers.TimeDistributed(tfk.layers.Dense(2, activation='softmax') ,name='output')(x)\n",
    "    \n",
    "    conv_model = tfk.models.Model([input1_, input2_, input3_], output_)\n",
    "    conv_model.compile(loss=NonZeroCCE(), metrics=[Accuracy], optimizer='adam', run_eagerly = True)\n",
    "    conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.load_weights(\"./GRN/IDRP/conv_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a223ce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************Conv ONLY*******************************************\n",
      "\n",
      "\n",
      "*******************************************VALIDATION*******************************************\n",
      "41/41 [==============================] - 5s 130ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96    276748\n",
      "           1       0.74      0.48      0.58     29082\n",
      "\n",
      "    accuracy                           0.93    305830\n",
      "   macro avg       0.84      0.73      0.77    305830\n",
      "weighted avg       0.93      0.93      0.93    305830\n",
      "\n",
      "[[271700   5048]\n",
      " [ 15006  14076]] 0.9344276231893536\n",
      "0.48401072828553743 0.9817595791116829 0.7328851536986102 0.5643108769274651 0.9282343561798985\n",
      "\n",
      "\n",
      "*******************************************Test*******************************************\n",
      "11/11 [==============================] - 8s 807ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87     47388\n",
      "           1       0.92      0.64      0.76     34221\n",
      "\n",
      "    accuracy                           0.83     81609\n",
      "   macro avg       0.85      0.80      0.81     81609\n",
      "weighted avg       0.84      0.83      0.82     81609\n",
      "\n",
      "[[45458  1930]\n",
      " [12185 22036]] 0.8270411351689152\n",
      "0.6439320884836797 0.9592723896345067 0.8016022390590931 0.65354279312198 0.8202434820226857\n"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************Conv ONLY*******************************************\")\n",
    "print()\n",
    "print()\n",
    "val_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv/val/\",padded_X2_val,padded_X4_val,padded_Y_val,30,False)\n",
    "print(\"*******************************************VALIDATION*******************************************\")\n",
    "preds = conv_model.predict(val_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_val, axis=-1)\n",
    "y_t = np.argmax(padded_Y_val[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n",
    "\n",
    "test_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv/test/\",padded_X2_te, padded_X4_te,padded_Y_te,30,False)\n",
    "print()\n",
    "print()\n",
    "print(\"*******************************************Test*******************************************\")\n",
    "preds = conv_model.predict(test_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_te, axis=-1)\n",
    "y_t = np.argmax(padded_Y_te[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbbecb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pssm (InputLayer)               [(None, 2000, 20)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 2000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 2000, 20)     0           pssm[0][0]                       \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "sequence_input (InputLayer)     [(None, 2000, 300)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 2000, 320)    0           multiply_32[0][0]                \n",
      "                                                                 sequence_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bigru1 (Bidirectional)          (None, 2000, 300)    424800      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 2000, 300)    0           bigru1[0][0]                     \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bigru2 (Bidirectional)          (None, 2000, 300)    406800      multiply_33[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 2000, 300)    0           bigru2[0][0]                     \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output1 (TimeDistributed)       (None, 2000, 500)    150500      multiply_34[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 2000, 500)    0           output1[0][0]                    \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output2 (TimeDistributed)       (None, 2000, 500)    250500      multiply_35[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output (TimeDistributed)        (None, 2000, 2)      1002        output2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,233,602\n",
      "Trainable params: 1,233,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.2602 - Accuracy: 0.8904 - val_loss: 0.2085 - val_Accuracy: 0.9287\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 57s 555ms/step - loss: 0.1954 - Accuracy: 0.9357 - val_loss: 0.2031 - val_Accuracy: 0.9301\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 53s 523ms/step - loss: 0.1989 - Accuracy: 0.9345 - val_loss: 0.1990 - val_Accuracy: 0.9303\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.1785 - Accuracy: 0.9397 - val_loss: 0.1999 - val_Accuracy: 0.9309\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 53s 524ms/step - loss: 0.1935 - Accuracy: 0.9341 - val_loss: 0.2007 - val_Accuracy: 0.9312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6b7401fac0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    input1_ = tfk.layers.Input(shape=(2000,300, ), name='sequence_input')\n",
    "    input2_ = tfk.layers.Input(shape=(2000,1, ), name='mask')\n",
    "    input3_ = tfk.layers.Input(shape=(2000,20, ), name='pssm')\n",
    "    \n",
    "    x = tfk.layers.Multiply()([input3_, input2_])\n",
    "    x = tfk.layers.concatenate([x, input1_], axis=-1)\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru2')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])    \n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output2')(x)\n",
    "    output_ = tfk.layers.TimeDistributed(tfk.layers.Dense(2, activation='softmax') ,name='output')(x)\n",
    "    \n",
    "    gru_model = tfk.models.Model([input1_, input2_, input3_], output_)\n",
    "    gru_model.compile(loss=NonZeroCCE(), metrics=[Accuracy], optimizer='adam', run_eagerly = True)\n",
    "    gru_model.summary()\n",
    "train_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/GRU/train/\",padded_X2, padded_X4, padded_Y,30,True)\n",
    "val_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/GRU/val/\",padded_X2_val,padded_X4_val, padded_Y_val,30,False)\n",
    "test_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/GRU/test/\",padded_X2_te, padded_X4_te, padded_Y_te,10,False)\n",
    "gru_model.fit(train_loader,steps_per_epoch=len(train_loader),\n",
    "                    verbose=1, epochs=5,\n",
    "                    validation_data = val_loader,validation_steps=len(val_loader),workers=4\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f33fd34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************GRU ONLY*******************************************\n",
      "\n",
      "\n",
      "*******************************************VALIDATION*******************************************\n",
      "41/41 [==============================] - 5s 122ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97    276748\n",
      "           1       0.81      0.42      0.55     29082\n",
      "\n",
      "    accuracy                           0.94    305830\n",
      "   macro avg       0.87      0.70      0.76    305830\n",
      "weighted avg       0.93      0.94      0.93    305830\n",
      "\n",
      "[[273803   2945]\n",
      " [ 16850  12232]] 0.9352744989046202\n",
      "0.42060380991678703 0.9893585500166217 0.7049811799667043 0.5537554238191598 0.9259000809323203\n",
      "\n",
      "\n",
      "*******************************************Test*******************************************\n",
      "11/11 [==============================] - 8s 800ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87     47388\n",
      "           1       0.93      0.65      0.76     34221\n",
      "\n",
      "    accuracy                           0.83     81609\n",
      "   macro avg       0.86      0.81      0.82     81609\n",
      "weighted avg       0.85      0.83      0.82     81609\n",
      "\n",
      "[[45707  1681]\n",
      " [12060 22161]] 0.8316239630432918\n",
      "0.6475848163408433 0.964526884443319 0.8060558503920812 0.6642016811608771 0.8248845273129719\n"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************GRU ONLY*******************************************\")\n",
    "print()\n",
    "print()\n",
    "val_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/GRU/val/\",padded_X2_val,padded_X4_val,padded_Y_val,30,False)\n",
    "print(\"*******************************************VALIDATION*******************************************\")\n",
    "preds = gru_model.predict(val_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_val, axis=-1)\n",
    "y_t = np.argmax(padded_Y_val[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n",
    "\n",
    "test_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/GRU/test/\",padded_X2_te, padded_X4_te,padded_Y_te,30,False)\n",
    "print()\n",
    "print()\n",
    "print(\"*******************************************Test*******************************************\")\n",
    "preds = gru_model.predict(test_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_te, axis=-1)\n",
    "y_t = np.argmax(padded_Y_te[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78a27be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pssm (InputLayer)               [(None, 2000, 20)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 2000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 2000, 20)     0           pssm[0][0]                       \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "sequence_input (InputLayer)     [(None, 2000, 600)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2000, 620)    0           multiply_4[0][0]                 \n",
      "                                                                 sequence_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bigru1 (Bidirectional)          (None, 2000, 300)    694800      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 2000, 300)    0           bigru1[0][0]                     \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bigru2 (Bidirectional)          (None, 2000, 300)    406800      multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 2000, 300)    0           bigru2[0][0]                     \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output1 (TimeDistributed)       (None, 2000, 500)    150500      multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 2000, 500)    0           output1[0][0]                    \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output2 (TimeDistributed)       (None, 2000, 500)    250500      multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (TimeDistributed)        (None, 2000, 2)      1002        output2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,503,602\n",
      "Trainable params: 1,503,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 392s 4s/step - loss: 0.2782 - Accuracy: 0.8784 - val_loss: 0.2119 - val_Accuracy: 0.9290\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 423s 4s/step - loss: 0.2033 - Accuracy: 0.9328 - val_loss: 0.2052 - val_Accuracy: 0.9299\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 432s 4s/step - loss: 0.1906 - Accuracy: 0.9367 - val_loss: 0.1976 - val_Accuracy: 0.9329\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 413s 4s/step - loss: 0.1750 - Accuracy: 0.9420 - val_loss: 0.1986 - val_Accuracy: 0.9324\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 359s 3s/step - loss: 0.2060 - Accuracy: 0.9328 - val_loss: 0.1977 - val_Accuracy: 0.9308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2b1c3175b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    input1_ = tfk.layers.Input(shape=(2000,600, ), name='sequence_input')\n",
    "    input2_ = tfk.layers.Input(shape=(2000,1, ), name='mask')\n",
    "    input3_ = tfk.layers.Input(shape=(2000,20, ), name='pssm')\n",
    "    \n",
    "    x = tfk.layers.Multiply()([input3_, input2_])\n",
    "    x = tfk.layers.concatenate([x, input1_], axis=-1)\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru2')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])    \n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output2')(x)\n",
    "    output_ = tfk.layers.TimeDistributed(tfk.layers.Dense(2, activation='softmax') ,name='output')(x)\n",
    "    \n",
    "    conv_GRU_model = tfk.models.Model([input1_, input2_, input3_], output_)\n",
    "    conv_GRU_model.compile(loss=NonZeroCCE(), metrics=[Accuracy], optimizer='adam', run_eagerly = True)\n",
    "    conv_GRU_model.summary()\n",
    "train_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv_GRU/train/\",padded_X2, padded_X4, padded_Y,30,True)\n",
    "val_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv_GRU/val/\",padded_X2_val,padded_X4_val, padded_Y_val,30,False)\n",
    "test_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv_GRU/test/\",padded_X2_te, padded_X4_te, padded_Y_te,10,False)\n",
    "conv_GRU_model.fit(train_loader,steps_per_epoch=len(train_loader),\n",
    "                    verbose=1, epochs=5,\n",
    "                    validation_data = val_loader,validation_steps=len(val_loader),workers=8\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d4fc97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************Conv_GRU ONLY*******************************************\n",
      "\n",
      "\n",
      "*******************************************VALIDATION*******************************************\n",
      "41/41 [==============================] - 13s 322ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    276748\n",
      "           1       0.77      0.46      0.58     29082\n",
      "\n",
      "    accuracy                           0.94    305830\n",
      "   macro avg       0.86      0.72      0.77    305830\n",
      "weighted avg       0.93      0.94      0.93    305830\n",
      "\n",
      "[[272728   4020]\n",
      " [ 15661  13421]] 0.9356472550109538\n",
      "0.4614882057630149 0.9854741497680201 0.7234811777655175 0.5653928226889657 0.9282588592135256\n",
      "\n",
      "\n",
      "*******************************************Test*******************************************\n",
      "11/11 [==============================] - 41s 4s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88     47388\n",
      "           1       0.90      0.71      0.79     34221\n",
      "\n",
      "    accuracy                           0.84     81609\n",
      "   macro avg       0.86      0.82      0.83     81609\n",
      "weighted avg       0.85      0.84      0.84     81609\n",
      "\n",
      "[[44763  2625]\n",
      " [10091 24130]] 0.8441838522711956\n",
      "0.7051225855468864 0.9446062294251709 0.8248644074860287 0.6829769347538069 0.8403337296712452\n"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************Conv_GRU ONLY*******************************************\")\n",
    "print()\n",
    "print()\n",
    "val_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv_GRU/val/\",padded_X2_val,padded_X4_val,padded_Y_val,30,False)\n",
    "print(\"*******************************************VALIDATION*******************************************\")\n",
    "preds = conv_GRU_model.predict(val_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_val, axis=-1)\n",
    "y_t = np.argmax(padded_Y_val[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n",
    "\n",
    "test_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv_GRU/test/\",padded_X2_te, padded_X4_te,padded_Y_te,30,False)\n",
    "print()\n",
    "print()\n",
    "print(\"*******************************************Test*******************************************\")\n",
    "preds = conv_GRU_model.predict(test_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_te, axis=-1)\n",
    "y_t = np.argmax(padded_Y_te[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "208c742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_model.save_weights(\"./GRN/IDRP/conv_model.h5\")\n",
    "# gru_model.save_weights(\"./GRN/IDRP/gru_model.h5\")\n",
    "# conv_GRU_model.save_weights(\"./GRN/IDRP/conv_gru_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406db89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
