{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c5adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 02:27:16.410534: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "from sklearn.metrics import *\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc58133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    #strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e371c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_aminoAcids = {0:'A', 1:'C', 2:'E', 3:'D', 4:'G', 5:'F', 6:'I', 7:'H', 8:'K', 9:'M', 10:'L',\n",
    "            11:'N', 12:'Q', 13:'P', 14:'S', 15:'R', 16:'T', 17:'W', 18:'V', 19:'Y', 20:'X'}\n",
    "embedding_keys = {\n",
    "        '<pad>':0,\n",
    "        'A':1,\n",
    "        'C':2,\n",
    "        'D':3,\n",
    "        'E':4,\n",
    "        'F':5,\n",
    "        'G':6,\n",
    "        'H':7,\n",
    "        'I':8,\n",
    "        'K':9,\n",
    "        'L':10,\n",
    "        'M':11,\n",
    "        'N':12,\n",
    "        'P':13,\n",
    "        'Q':14,\n",
    "        'R':15,\n",
    "        'S':16,\n",
    "        'T':17,\n",
    "        'V':18,\n",
    "        'W':19,\n",
    "        'X':20,\n",
    "        'Y':21,\n",
    "        'B':22,\n",
    "        'U':23,\n",
    "        'Z':24,\n",
    "        'O':25,\n",
    "        '<mask>':26}\n",
    "embedding_list = list(embedding_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18cab4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonZeroCCE(tf.keras.losses.Loss):\n",
    "    def __init__(self,Weights=[],smoothing = None):\n",
    "        super().__init__()\n",
    "        if smoothing is not None:\n",
    "            self.cce = tf.keras.losses.CategoricalCrossentropy(reduction='none', label_smoothing=smoothing)\n",
    "        else:\n",
    "            self.cce = tf.keras.losses.CategoricalCrossentropy(reduction='none')\n",
    "        self.weights = np.array(Weights)\n",
    "    def call(self, y_true, y_pred):\n",
    "        if len(self.weights)>0:\n",
    "            loss = self.cce(self.weights*y_true,y_pred)\n",
    "        else:\n",
    "            loss = self.cce(y_true,y_pred)\n",
    "        return tf.math.reduce_sum(loss)/((y_true.shape[0]*y_true.shape[1])-float(tf.math.reduce_sum(tf.cast(tf.equal(tf.math.reduce_sum(y_true,-1),0),tf.int32))))\n",
    "\n",
    "def Accuracy(y_true,y_pred):\n",
    "    y_true = y_true.numpy()\n",
    "    y_pred = y_pred.numpy()\n",
    "\n",
    "    m = np.sum(y_true, axis=-1)\n",
    "    y_t = np.argmax(y_true[m==1],axis=-1)\n",
    "    y_p = np.argmax(y_pred[m==1],axis=-1)\n",
    "    return accuracy_score(y_t,y_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a8686c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 1862, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = np.load('./Data/Disordered_Regions_Train_Dataset.npz')\n",
    "X = tmp['sequences']\n",
    "X = np.argmax(X,axis=-1)\n",
    "X_p = tmp['pssms']\n",
    "Y = tmp['regions']\n",
    "X_m = X!=0\n",
    "X_m = X_m.astype(np.int32)\n",
    "X_i = np.repeat(np.arange(1,X.shape[1]+1)[None,:], X.shape[0], axis=0)\n",
    "X_i[X==0] = 0\n",
    "max_len = X.shape[1]\n",
    "\n",
    "train_ids = []\n",
    "with open('./Data/DM3000_id.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        if l[:3] == 'Dis':\n",
    "            k = l.split('|')[1].split()[0]\n",
    "        else:\n",
    "            k = l.split()[0]\n",
    "        train_ids += [k]\n",
    "val_ids = []\n",
    "with open('./Data/DM1229_id.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        if l[:3] == 'Dis':\n",
    "            k = l.split('|')[1].split()[0]\n",
    "        else:\n",
    "            k = l.split()[0]\n",
    "        val_ids += [k]\n",
    "a = tmp['seq_ids']\n",
    "tr_ids_m = [True if i in train_ids else False for i in a]\n",
    "val_ids_m = [True if i in val_ids else False for i in a]\n",
    "len(val_ids),len(train_ids)\n",
    "\n",
    "X1_val = X[val_ids_m][:,1:1863]\n",
    "X4_val = X_m[val_ids_m][:,1:1863]\n",
    "X2_val = X_p[val_ids_m][:,1:1863]\n",
    "X3_val = X_i[val_ids_m][:,1:1863]\n",
    "Y_val = Y[val_ids_m][:,1:1863]\n",
    "X4_val = np.expand_dims(X4_val,-1)\n",
    "X4_val.shape\n",
    "#X1_val[X1_val==23]=0\n",
    "\n",
    "\n",
    "X1 = X[tr_ids_m][:,1:1863]\n",
    "X4 = X_m[tr_ids_m][:,1:1863]\n",
    "X2 = X_p[tr_ids_m][:,1:1863]\n",
    "X3 = X_i[tr_ids_m][:,1:1863]\n",
    "Y = Y[tr_ids_m][:,1:1863]\n",
    "\n",
    "X4 = np.expand_dims(X4,-1)\n",
    "X4.shape\n",
    "\n",
    "tmp = np.load('./Data/Disordered_Regions_Test_Dataset.npz')\n",
    "test_ids = []\n",
    "with open('./Data/SL329_id.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        k = l.split('|')[1].split()[0]\n",
    "        test_ids += [k]\n",
    "te_ids_m = [True if i in test_ids else False for i in tmp['seq_ids']]\n",
    "X1_te = np.argmax(tmp['sequences'],axis=-1)[te_ids_m][:,1:1863]\n",
    "X2_te = tmp['pssms'][te_ids_m][:,1:1863]\n",
    "Y_te = tmp['regions'][te_ids_m][:,1:1863]\n",
    "X_m_te = X1_te!=0\n",
    "X4_te = X_m_te.astype(np.int32)\n",
    "X4_te = np.expand_dims(X4_te,-1)\n",
    "X4_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0169bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 02:27:42.234124: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-04-30 02:27:42.234225: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: cbrls0\n",
      "2023-04-30 02:27:42.234253: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: cbrls0\n",
      "2023-04-30 02:27:42.234455: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.182.3\n",
      "2023-04-30 02:27:42.234514: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.182.3\n",
      "2023-04-30 02:27:42.234532: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.182.3\n",
      "2023-04-30 02:27:42.234992: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "X1_temp = []\n",
    "for seq in X1:\n",
    "    end = np.where(seq==23)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(seq)\n",
    "    else:\n",
    "        end = end[0]\n",
    "    X1_temp.append([embedding_keys[num_aminoAcids[seq[idx]-1]] for idx in range(0,end)])\n",
    "    X1_temp[-1].extend([0]*(2000-len(X1_temp[-1])))\n",
    "    X1_temp[-1] = np.array(X1_temp[-1])\n",
    "X1_temp = np.array(X1_temp)\n",
    "\n",
    "X1_val_temp = []\n",
    "for seq in X1_val:\n",
    "    end = np.where(seq==23)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(seq)\n",
    "    else:\n",
    "        end = end[0]\n",
    "    X1_val_temp.append([embedding_keys[num_aminoAcids[seq[idx]-1]] for idx in range(0,end)])\n",
    "    X1_val_temp[-1].extend([0]*(2000-len(X1_val_temp[-1])))\n",
    "    X1_val_temp[-1] = np.array(X1_val_temp[-1])\n",
    "X1_val_temp = np.array(X1_val_temp)\n",
    "\n",
    "X1_te_temp = []\n",
    "for seq in X1_te:\n",
    "    end = np.where(seq==23)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(seq)\n",
    "    else:\n",
    "        end = end[0]\n",
    "    X1_te_temp.append([embedding_keys[num_aminoAcids[seq[idx]-1]] for idx in range(0,end)])\n",
    "    X1_te_temp[-1].extend([0]*(2000-len(X1_te_temp[-1])))\n",
    "    X1_te_temp[-1] = np.array(X1_te_temp[-1])\n",
    "X1_te_temp = np.array(X1_te_temp)\n",
    "\n",
    "X1_temp_oneHot = np.array(tf.one_hot(X1_temp,len(embedding_keys))[:,:,1:])\n",
    "X1_val_temp_oneHot = np.array(tf.one_hot(X1_val_temp,len(embedding_keys))[:,:,1:])\n",
    "X1_te_temp_oneHot = np.array(tf.one_hot(X1_te_temp,len(embedding_keys))[:,:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c43d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embeddingLoader(tfk.utils.Sequence):\n",
    "    def __init__(self,path,pssms, masks,Y_oneHot,batch_size=30,shuffle=True):\n",
    "        self.path = path\n",
    "        self.pssms = pssms\n",
    "        self.masks = masks\n",
    "        self.Y_oneHot = copy.deepcopy(np.array(Y_oneHot))\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.length = len(Y_oneHot)\n",
    "        self.indices = np.arange(0,self.length)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def generate_batches(self):\n",
    "        self.Y_oneHot_ = self.Y_oneHot[self.indices]\n",
    "        self.pssms_ = self.pssms[self.indices]\n",
    "        self.masks_ = self.masks[self.indices]\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        self.generate_batches()\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        token_representations = []\n",
    "        for idx in self.indices[index*self.batch_size:(index+1)*self.batch_size]:\n",
    "            token_representations.append(np.load(self.path+str(idx).zfill(6)+'.npy')[0])\n",
    "        return ([\n",
    "                tf.convert_to_tensor(np.array(token_representations)),\n",
    "                self.masks_[index*self.batch_size:(index+1)*self.batch_size],\n",
    "                self.pssms_[index*self.batch_size:(index+1)*self.batch_size]\n",
    "                ],\n",
    "                self.Y_oneHot_[index*self.batch_size:(index+1)*self.batch_size]\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        if self.length%self.batch_size!=0:\n",
    "            return 1+(self.length//self.batch_size)\n",
    "        return self.length//self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63308773",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_Y = np.zeros((3000, 2000, 2))\n",
    "padded_Y[:Y.shape[0],:Y.shape[1],:Y.shape[2]] = Y\n",
    "\n",
    "padded_Y_val = np.zeros((1229, 2000, 2))\n",
    "padded_Y_val[:Y_val.shape[0],:Y_val.shape[1],:Y_val.shape[2]] = Y_val\n",
    "\n",
    "\n",
    "padded_Y_te = np.zeros((318, 2000, 2))\n",
    "padded_Y_te[:Y_te.shape[0],:Y_te.shape[1],:Y_te.shape[2]] = Y_te\n",
    "\n",
    "padded_X2 = np.zeros((3000, 2000, 20))\n",
    "padded_X2[:X2.shape[0],:X2.shape[1],:X2.shape[2]] = X2\n",
    "\n",
    "padded_X2_val = np.zeros((1229, 2000, 20))\n",
    "padded_X2_val[:X2_val.shape[0],:X2_val.shape[1],:X2_val.shape[2]] = X2_val\n",
    "\n",
    "\n",
    "padded_X2_te = np.zeros((318, 2000, 20))\n",
    "padded_X2_te[:X2_te.shape[0],:X2_te.shape[1],:X2_te.shape[2]] = X2_te\n",
    "\n",
    "padded_X4 = np.zeros((3000, 2000, 1))\n",
    "padded_X4[:X4.shape[0],:X4.shape[1],:X4.shape[2]] = X4\n",
    "\n",
    "padded_X4_val = np.zeros((1229, 2000, 1))\n",
    "padded_X4_val[:X4_val.shape[0],:X4_val.shape[1],:X4_val.shape[2]] = X4_val\n",
    "\n",
    "\n",
    "padded_X4_te = np.zeros((318, 2000, 1))\n",
    "padded_X4_te[:X4_te.shape[0],:X4_te.shape[1],:X4_te.shape[2]] = X4_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a15c9ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence_input (InputLayer)    [(None, 2000, 300)]  0           []                               \n",
      "                                                                                                  \n",
      " mask (InputLayer)              [(None, 2000, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 2000, 300)    0           ['sequence_input[0][0]',         \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru1 (Bidirectional)         (None, 2000, 300)    406800      ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 2000, 300)    0           ['bigru1[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru2 (Bidirectional)         (None, 2000, 300)    406800      ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 2000, 300)    0           ['bigru2[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output1 (TimeDistributed)      (None, 2000, 500)    150500      ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 2000, 500)    0           ['output1[0][0]',                \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output2 (TimeDistributed)      (None, 2000, 500)    250500      ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " pssm (InputLayer)              [(None, 2000, 20)]   0           []                               \n",
      "                                                                                                  \n",
      " output (TimeDistributed)       (None, 2000, 2)      1002        ['output2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,215,602\n",
      "Trainable params: 1,215,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    input1_ = tfk.layers.Input(shape=(2000,300, ), name='sequence_input')\n",
    "    input2_ = tfk.layers.Input(shape=(2000,1, ), name='mask')\n",
    "    input3_ = tfk.layers.Input(shape=(2000,20, ), name='pssm')\n",
    "\n",
    "    x = tfk.layers.Multiply()([input1_, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru2')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output2')(x)\n",
    "    output_ = tfk.layers.TimeDistributed(tfk.layers.Dense(2, activation='softmax') ,name='output')(x)\n",
    "    \n",
    "    conv_model = tfk.models.Model([input1_, input2_, input3_], output_)\n",
    "    conv_model.compile(loss=NonZeroCCE(), metrics=[Accuracy], optimizer='adam', run_eagerly = True)\n",
    "    conv_model.summary()\n",
    "conv_model.load_weights(\"./Weights/conv_model.h5\")\n",
    "# train_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv/train/\",padded_X2, padded_X4, padded_Y,30,True)\n",
    "# val_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv/val/\",padded_X2_val,padded_X4_val, padded_Y_val,30,False)\n",
    "# test_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv/test/\",padded_X2_te, padded_X4_te, padded_Y_te,10,False)\n",
    "# conv_model.fit(train_loader,steps_per_epoch=len(train_loader),\n",
    "#                     verbose=1, epochs=5,\n",
    "#                     validation_data = val_loader,validation_steps=len(val_loader),workers=4\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e79b03a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************Conv ONLY*******************************************\n",
      "\n",
      "\n",
      "*******************************************VALIDATION*******************************************\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data/Embedder/val/000000.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m embeddingLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Data/Embedder/val/\u001b[39m\u001b[38;5;124m\"\u001b[39m,padded_X2_val,padded_X4_val,padded_Y_val,\u001b[38;5;241m30\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*******************************************VALIDATION*******************************************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mconv_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(padded_Y_val, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m y_t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(padded_Y_val[m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_hamza/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn [7], line 25\u001b[0m, in \u001b[0;36membeddingLoader.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     23\u001b[0m token_representations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[index\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:(index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]:\n\u001b[0;32m---> 25\u001b[0m     token_representations\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzfill\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([\n\u001b[1;32m     27\u001b[0m         tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(np\u001b[38;5;241m.\u001b[39marray(token_representations)),\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasks_[index\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:(index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_oneHot_[index\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:(index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[1;32m     32\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_hamza/lib/python3.10/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Data/Embedder/val/000000.npy'"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************Conv ONLY*******************************************\")\n",
    "print()\n",
    "print()\n",
    "val_loader = embeddingLoader(\"./Data/Embedder/val/\",padded_X2_val,padded_X4_val,padded_Y_val,30,False)\n",
    "print(\"*******************************************VALIDATION*******************************************\")\n",
    "preds = conv_model.predict(val_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_val, axis=-1)\n",
    "y_t = np.argmax(padded_Y_val[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n",
    "\n",
    "test_loader = embeddingLoader(\"./Data/Embedder/test/\",padded_X2_te, padded_X4_te,padded_Y_te,30,False)\n",
    "print()\n",
    "print()\n",
    "print(\"*******************************************Test*******************************************\")\n",
    "preds = conv_model.predict(test_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_te, axis=-1)\n",
    "y_t = np.argmax(padded_Y_te[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcee292c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence_input (InputLayer)     [(None, 2000, 300)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 2000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 2000, 300)    0           sequence_input[0][0]             \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bigru1 (Bidirectional)          (None, 2000, 300)    406800      multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 2000, 300)    0           bigru1[0][0]                     \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bigru2 (Bidirectional)          (None, 2000, 300)    406800      multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 2000, 300)    0           bigru2[0][0]                     \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output1 (TimeDistributed)       (None, 2000, 500)    150500      multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 2000, 500)    0           output1[0][0]                    \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output2 (TimeDistributed)       (None, 2000, 500)    250500      multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pssm (InputLayer)               [(None, 2000, 20)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "output (TimeDistributed)        (None, 2000, 2)      1002        output2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,215,602\n",
      "Trainable params: 1,215,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 228s 2s/step - loss: 0.2652 - Accuracy: 0.8859 - val_loss: 0.2151 - val_Accuracy: 0.9271\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 220s 2s/step - loss: 0.2060 - Accuracy: 0.9311 - val_loss: 0.2224 - val_Accuracy: 0.9270\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 224s 2s/step - loss: 0.1967 - Accuracy: 0.9352 - val_loss: 0.2104 - val_Accuracy: 0.9279\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 229s 2s/step - loss: 0.1928 - Accuracy: 0.9353 - val_loss: 0.2221 - val_Accuracy: 0.9278\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 228s 2s/step - loss: 0.1890 - Accuracy: 0.9366 - val_loss: 0.2113 - val_Accuracy: 0.9273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa7d08fa5e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    input1_ = tfk.layers.Input(shape=(2000,300, ), name='sequence_input')\n",
    "    input2_ = tfk.layers.Input(shape=(2000,1, ), name='mask')\n",
    "    input3_ = tfk.layers.Input(shape=(2000,20, ), name='pssm')\n",
    "    \n",
    "    x = tfk.layers.Multiply()([input1_, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru2')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output2')(x)\n",
    "    output_ = tfk.layers.TimeDistributed(tfk.layers.Dense(2, activation='softmax') ,name='output')(x)\n",
    "    \n",
    "    gru_model = tfk.models.Model([input1_, input2_, input3_], output_)\n",
    "    gru_model.compile(loss=NonZeroCCE(), metrics=[Accuracy], optimizer='adam', run_eagerly = True)\n",
    "    gru_model.summary()\n",
    "train_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/GRU/train/\",padded_X2, padded_X4, padded_Y,30,True)\n",
    "val_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/GRU/val/\",padded_X2_val,padded_X4_val, padded_Y_val,30,False)\n",
    "test_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/GRU/test/\",padded_X2_te, padded_X4_te, padded_Y_te,10,False)\n",
    "gru_model.fit(train_loader,steps_per_epoch=len(train_loader),\n",
    "                    verbose=1, epochs=5,\n",
    "                    validation_data = val_loader,validation_steps=len(val_loader),workers=4\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54a03fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************GRU ONLY*******************************************\n",
      "\n",
      "\n",
      "*******************************************VALIDATION*******************************************\n",
      "41/41 [==============================] - 192s 5s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96    276748\n",
      "           1       0.84      0.36      0.50     29082\n",
      "\n",
      "    accuracy                           0.93    305830\n",
      "   macro avg       0.89      0.68      0.73    305830\n",
      "weighted avg       0.93      0.93      0.92    305830\n",
      "\n",
      "[[274695   2053]\n",
      " [ 18680  10402]] 0.9322074355033843\n",
      "0.3576782889759989 0.9925816988740659 0.6751299939250324 0.5198301820047131 0.9196275139719491\n",
      "\n",
      "\n",
      "*******************************************Test*******************************************\n",
      "11/11 [==============================] - 68s 7s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.98      0.86     47388\n",
      "           1       0.95      0.60      0.73     34221\n",
      "\n",
      "    accuracy                           0.82     81609\n",
      "   macro avg       0.86      0.79      0.80     81609\n",
      "weighted avg       0.84      0.82      0.81     81609\n",
      "\n",
      "[[46240  1148]\n",
      " [13858 20363]] 0.8161232217034886\n",
      "0.5950439788434002 0.975774457668608 0.7854092182560042 0.639319895630216 0.8060276752257438\n"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************GRU ONLY*******************************************\")\n",
    "print()\n",
    "print()\n",
    "val_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/GRU/val/\",padded_X2_val,padded_X4_val,padded_Y_val,30,False)\n",
    "print(\"*******************************************VALIDATION*******************************************\")\n",
    "preds = gru_model.predict(val_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_val, axis=-1)\n",
    "y_t = np.argmax(padded_Y_val[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n",
    "\n",
    "test_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/GRU/test/\",padded_X2_te, padded_X4_te,padded_Y_te,30,False)\n",
    "print()\n",
    "print()\n",
    "print(\"*******************************************Test*******************************************\")\n",
    "preds = gru_model.predict(test_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_te, axis=-1)\n",
    "y_t = np.argmax(padded_Y_te[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd65e140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence_input (InputLayer)     [(None, 2000, 600)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 2000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 2000, 600)    0           sequence_input[0][0]             \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bigru1 (Bidirectional)          (None, 2000, 300)    676800      multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 2000, 300)    0           bigru1[0][0]                     \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bigru2 (Bidirectional)          (None, 2000, 300)    406800      multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 2000, 300)    0           bigru2[0][0]                     \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output1 (TimeDistributed)       (None, 2000, 500)    150500      multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 2000, 500)    0           output1[0][0]                    \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output2 (TimeDistributed)       (None, 2000, 500)    250500      multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pssm (InputLayer)               [(None, 2000, 20)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "output (TimeDistributed)        (None, 2000, 2)      1002        output2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,485,602\n",
      "Trainable params: 1,485,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 423s 4s/step - loss: 0.2842 - Accuracy: 0.8775 - val_loss: 0.2082 - val_Accuracy: 0.9285\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 433s 4s/step - loss: 0.2048 - Accuracy: 0.9323 - val_loss: 0.2102 - val_Accuracy: 0.9290\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 423s 4s/step - loss: 0.2088 - Accuracy: 0.9304 - val_loss: 0.2090 - val_Accuracy: 0.9294\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 377s 4s/step - loss: 0.1963 - Accuracy: 0.9339 - val_loss: 0.2034 - val_Accuracy: 0.9301\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 321s 3s/step - loss: 0.1932 - Accuracy: 0.9345 - val_loss: 0.2043 - val_Accuracy: 0.9303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa7d08f4070>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    input1_ = tfk.layers.Input(shape=(2000,600, ), name='sequence_input')\n",
    "    input2_ = tfk.layers.Input(shape=(2000,1, ), name='mask')\n",
    "    input3_ = tfk.layers.Input(shape=(2000,20, ), name='pssm')\n",
    "    \n",
    "    x = tfk.layers.Multiply()([input1_, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru2')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output2')(x)\n",
    "    output_ = tfk.layers.TimeDistributed(tfk.layers.Dense(2, activation='softmax') ,name='output')(x)\n",
    "    \n",
    "    conv_GRU_model = tfk.models.Model([input1_, input2_, input3_], output_)\n",
    "    conv_GRU_model.compile(loss=NonZeroCCE(), metrics=[Accuracy], optimizer='adam', run_eagerly = True)\n",
    "    conv_GRU_model.summary()\n",
    "train_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv_GRU/train/\",padded_X2, padded_X4, padded_Y,30,True)\n",
    "val_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv_GRU/val/\",padded_X2_val,padded_X4_val, padded_Y_val,30,False)\n",
    "test_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv_GRU/test/\",padded_X2_te, padded_X4_te, padded_Y_te,10,False)\n",
    "conv_GRU_model.fit(train_loader,steps_per_epoch=len(train_loader),\n",
    "                    verbose=1, epochs=5,\n",
    "                    validation_data = val_loader,validation_steps=len(val_loader),workers=4\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce30fa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************Conv_GRU ONLY*******************************************\n",
      "\n",
      "\n",
      "*******************************************VALIDATION*******************************************\n",
      "41/41 [==============================] - 259s 6s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96    276748\n",
      "           1       0.82      0.40      0.54     29082\n",
      "\n",
      "    accuracy                           0.93    305830\n",
      "   macro avg       0.88      0.70      0.75    305830\n",
      "weighted avg       0.93      0.93      0.92    305830\n",
      "\n",
      "[[274107   2641]\n",
      " [ 17399  11683]] 0.9344734002550437\n",
      "0.40172615363455055 0.9904570222729704 0.6960915879537605 0.5444868988106968 0.9241847969658966\n",
      "\n",
      "\n",
      "*******************************************Test*******************************************\n",
      "11/11 [==============================] - 76s 8s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86     47388\n",
      "           1       0.95      0.61      0.74     34221\n",
      "\n",
      "    accuracy                           0.82     81609\n",
      "   macro avg       0.86      0.79      0.80     81609\n",
      "weighted avg       0.85      0.82      0.81     81609\n",
      "\n",
      "[[46189  1199]\n",
      " [13371 20850]] 0.8214657697067725\n",
      "0.6092750065749102 0.9746982358402971 0.7919866212076037 0.6489357392615125 0.8123157226365402\n"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************Conv_GRU ONLY*******************************************\")\n",
    "print()\n",
    "print()\n",
    "val_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv_GRU/val/\",padded_X2_val,padded_X4_val,padded_Y_val,30,False)\n",
    "print(\"*******************************************VALIDATION*******************************************\")\n",
    "preds = conv_GRU_model.predict(val_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_val, axis=-1)\n",
    "y_t = np.argmax(padded_Y_val[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n",
    "\n",
    "test_loader = embeddingLoader(\"../MLM_Embedder/IDRP/CGRN/Conv_GRU/test/\",padded_X2_te, padded_X4_te,padded_Y_te,30,False)\n",
    "print()\n",
    "print()\n",
    "print(\"*******************************************Test*******************************************\")\n",
    "preds = conv_GRU_model.predict(test_loader, verbose=1)\n",
    "\n",
    "m = np.sum(padded_Y_te, axis=-1)\n",
    "y_t = np.argmax(padded_Y_te[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[0][1],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[1][0],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65be2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.save_weights(\"./GRN/IDRP/conv_model.h5\")\n",
    "gru_model.save_weights(\"./GRN/IDRP/gru_model.h5\")\n",
    "conv_GRU_model.save_weights(\"./GRN/IDRP/conv_gru_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d22e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
