{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T03:17:03.212099Z",
     "iopub.status.busy": "2020-11-18T03:17:03.211367Z",
     "iopub.status.idle": "2020-11-18T03:17:10.667055Z",
     "shell.execute_reply": "2020-11-18T03:17:10.665387Z"
    },
    "papermill": {
     "duration": 7.474406,
     "end_time": "2020-11-18T03:17:10.667188",
     "exception": false,
     "start_time": "2020-11-18T03:17:03.192782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T03:17:10.700990Z",
     "iopub.status.busy": "2020-11-18T03:17:10.700127Z",
     "iopub.status.idle": "2020-11-18T03:17:18.212163Z",
     "shell.execute_reply": "2020-11-18T03:17:18.211331Z"
    },
    "papermill": {
     "duration": 7.532164,
     "end_time": "2020-11-18T03:17:18.212956",
     "exception": false,
     "start_time": "2020-11-18T03:17:10.680792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = np.load('Data/Disordered_Regions_Train_Dataset.npz')\n",
    "X = tmp['sequences']\n",
    "X = np.argmax(X,axis=-1)\n",
    "X_p = tmp['pssms']\n",
    "Y = tmp['regions']\n",
    "X_m = X!=0\n",
    "X_m = X_m.astype(np.int32)\n",
    "X_i = np.repeat(np.arange(1,X.shape[1]+1)[None,:], X.shape[0], axis=0)\n",
    "X_i[X==0] = 0\n",
    "max_len = X.shape[1]\n",
    "\n",
    "train_ids = []\n",
    "with open('Data/DM3000_id.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        if l[:3] == 'Dis':\n",
    "            k = l.split('|')[1].split()[0]\n",
    "        else:\n",
    "            k = l.split()[0]\n",
    "        train_ids += [k]\n",
    "val_ids = []\n",
    "with open('Data/DM1229_id.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        if l[:3] == 'Dis':\n",
    "            k = l.split('|')[1].split()[0]\n",
    "        else:\n",
    "            k = l.split()[0]\n",
    "        val_ids += [k]\n",
    "a = tmp['seq_ids']\n",
    "tr_ids_m = [True if i in train_ids else False for i in a]\n",
    "val_ids_m = [True if i in val_ids else False for i in a]\n",
    "len(val_ids),len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T03:17:18.294205Z",
     "iopub.status.busy": "2020-11-18T03:17:18.293100Z",
     "iopub.status.idle": "2020-11-18T03:17:18.306262Z",
     "shell.execute_reply": "2020-11-18T03:17:18.307958Z"
    },
    "papermill": {
     "duration": 0.049701,
     "end_time": "2020-11-18T03:17:18.308158",
     "exception": false,
     "start_time": "2020-11-18T03:17:18.258457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_val = X[val_ids_m]\n",
    "X_m_val = X_m[val_ids_m]\n",
    "X_p_val = X_p[val_ids_m]\n",
    "X_i_val = X_i[val_ids_m]\n",
    "Y_val = Y[val_ids_m]\n",
    "X = X[tr_ids_m]\n",
    "X_m = X_m[tr_ids_m]\n",
    "X_p = X_p[tr_ids_m]\n",
    "X_i = X_i[tr_ids_m]\n",
    "Y = Y[tr_ids_m]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T03:17:18.358105Z",
     "iopub.status.busy": "2020-11-18T03:17:18.357196Z",
     "iopub.status.idle": "2020-11-18T03:17:18.369581Z",
     "shell.execute_reply": "2020-11-18T03:17:18.368768Z"
    },
    "papermill": {
     "duration": 0.040493,
     "end_time": "2020-11-18T03:17:18.369758",
     "exception": false,
     "start_time": "2020-11-18T03:17:18.329265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T03:17:18.421017Z",
     "iopub.status.busy": "2020-11-18T03:17:18.419981Z",
     "iopub.status.idle": "2020-11-18T03:17:18.466425Z",
     "shell.execute_reply": "2020-11-18T03:17:18.467330Z"
    },
    "papermill": {
     "duration": 0.077994,
     "end_time": "2020-11-18T03:17:18.467526",
     "exception": false,
     "start_time": "2020-11-18T03:17:18.389532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shape_list(x):\n",
    "    tmp = list(K.int_shape(x))\n",
    "    tmp[0] = -1\n",
    "    return tmp\n",
    "\n",
    "def dot_product_attention(q, k, v):\n",
    "    depth = K.int_shape(q)[-1]\n",
    "    dots = tf.matmul(q, k, transpose_b=True) /  tf.sqrt(float(depth))\n",
    "    logsumexp = tf.math.reduce_logsumexp(dots, axis=-1, keepdims=True)\n",
    "    dots = tf.exp(dots - logsumexp)\n",
    "    attn = tf.matmul(dots, v)\n",
    "    return attn\n",
    "\n",
    "def prepare_dpa(x, n_heads, d_head):\n",
    "    s_l = K.int_shape(x)[1]\n",
    "    x = tf.reshape(x, (-1, s_l, n_heads, d_head))\n",
    "    x = tf.transpose(x, (0, 2, 1, 3))\n",
    "    x = tf.reshape(x, (-1, s_l, d_head))\n",
    "    return x\n",
    "\n",
    "def post_dpa(x, n_heads, d_head):\n",
    "    s_l = K.int_shape(x)[1]\n",
    "    x = tf.reshape(x, (-1, n_heads, s_l, d_head))\n",
    "    x = tf.reshape(x, (-1, s_l, n_heads*d_head))\n",
    "    return x\n",
    "\n",
    "def enc_dec_attention(x, y, d_feat, n_heads):\n",
    "    d_head = d_feat // n_heads\n",
    "    q = tfk.layers.TimeDistributed(tfk.layers.Dense(d_feat))(y)\n",
    "    q = prepare_dpa(q, n_heads, d_head)\n",
    "    k = tfk.layers.TimeDistributed(tfk.layers.Dense(d_feat))(x)\n",
    "    k = prepare_dpa(k, n_heads, d_head)\n",
    "    v = tfk.layers.TimeDistributed(tfk.layers.Dense(d_feat))(x)\n",
    "    v = prepare_dpa(v, n_heads, d_head)\n",
    "    x = dot_product_attention(q, k, v)\n",
    "    x = post_dpa(x, n_heads, d_head)\n",
    "    return x\n",
    "\n",
    "def casual_attention(x, d_feat, n_heads):\n",
    "    d_head = d_feat // n_heads\n",
    "    q = tfk.layers.TimeDistributed(tfk.layers.Dense(d_feat))(x)\n",
    "    q = prepare_dpa(q, n_heads, d_head)\n",
    "    k = tfk.layers.TimeDistributed(tfk.layers.Dense(d_feat))(x)\n",
    "    k = prepare_dpa(k, n_heads, d_head)\n",
    "    v = tfk.layers.TimeDistributed(tfk.layers.Dense(d_feat))(x)\n",
    "    v = prepare_dpa(v, n_heads, d_head)\n",
    "    x = dot_product_attention(q, k, v)\n",
    "    x = post_dpa(x, n_heads, d_head)\n",
    "    return x\n",
    "\n",
    "def feed_forward(x, n_units, d_ff, d_rate):\n",
    "    x = tfk.layers.LayerNormalization()(x)\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(d_ff, activation='relu'))(x)\n",
    "    x = tfk.layers.Dropout(d_rate)(x)\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(n_units, activation='relu'))(x)\n",
    "    x = tfk.layers.Dropout(d_rate)(x)\n",
    "    return x\n",
    "\n",
    "def decoder_block(x, z, n_units, d_ff, n_heads, d_rate):\n",
    "    x = tfk.layers.LayerNormalization()(x)\n",
    "    y = casual_attention(x, n_units, n_heads)\n",
    "    y = tfk.layers.Dropout(d_rate)(y)\n",
    "    x = tfk.layers.add([x,y])\n",
    "    x = tfk.layers.LayerNormalization()(x)\n",
    "    y = enc_dec_attention(z, x, n_units, n_heads)\n",
    "    y = tfk.layers.Dropout(d_rate)(y)\n",
    "    x = tfk.layers.add([x,y])\n",
    "    y = feed_forward(x, n_units, d_ff, d_rate)\n",
    "    y = tfk.layers.add([x,y])\n",
    "    return y\n",
    "\n",
    "def encoder_block(x, n_units, d_ff, n_heads, d_rate):\n",
    "    x = tfk.layers.LayerNormalization()(x)\n",
    "    y = casual_attention(x, n_units, n_heads)\n",
    "    y = tfk.layers.Dropout(d_rate)(y)\n",
    "    x = tfk.layers.add([x,y])\n",
    "    y = feed_forward(x, n_units, d_ff, d_rate)\n",
    "    y = tfk.layers.add([x,y])\n",
    "    return y\n",
    "\n",
    "def _getPosEncodingMat(length, dim):\n",
    "    posEnc = np.array([[pos/np.power(10000, 2*(j//2)/dim) for j in range(dim)]\n",
    "                        if pos!=0 else np.zeros(dim) for pos in range(length)], dtype=np.float32)\n",
    "    posEnc[1:, 0::2] = np.sin(posEnc[1:, 0::2])\n",
    "    posEnc[1:, 1::2] = np.cos(posEnc[1:, 1::2])\n",
    "    return posEnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T03:17:18.519733Z",
     "iopub.status.busy": "2020-11-18T03:17:18.518767Z",
     "iopub.status.idle": "2020-11-18T03:17:20.108502Z",
     "shell.execute_reply": "2020-11-18T03:17:20.109487Z"
    },
    "papermill": {
     "duration": 1.620836,
     "end_time": "2020-11-18T03:17:20.109691",
     "exception": false,
     "start_time": "2020-11-18T03:17:18.488855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    input1 = tfk.layers.Input(shape=(max_len, ), name='sequence_input')\n",
    "    input2 = tfk.layers.Input(shape=(max_len, 20, ), name='pssm_input')\n",
    "    input3 = tfk.layers.Input(shape=(max_len, ), name='pid_input')\n",
    "    input4 = tfk.layers.Input(shape=(max_len, ), name='mask_input')\n",
    "    \n",
    "    emb = tfk.layers.Embedding(input_dim=24, output_dim=100, name='embds')(input1)\n",
    "    pidsEmbd = tfk.layers.Embedding(input_dim=max_len, output_dim=100, trainable=False, \n",
    "                                    weights=[_getPosEncodingMat(max_len, 100)], name='pids_embds')(input3)\n",
    "    emb = tfk.layers.Add(name='seq_embdAdd')([emb, pidsEmbd])\n",
    "    xm = tfk.layers.Reshape((-1,1))(input4)\n",
    "    \n",
    "    x = tfk.layers.concatenate([emb, input2], axis=-1, name='con1')\n",
    "    x = tfk.layers.Conv1D(200, 30, strides=1, padding='same', activation='relu')(x)\n",
    "    x = tfk.layers.Multiply()([x,xm])\n",
    "    \n",
    "    for _ in range(3):\n",
    "        x = encoder_block(x, 200, 512, 4, 0.2)\n",
    "\n",
    "    model = tfk.layers.TimeDistributed( tfk.layers.Dense(200, activation='relu'), name='output1')(x)\n",
    "    model = tfk.layers.TimeDistributed( tfk.layers.Dense(200, activation='relu'), name='output2')(model)\n",
    "\n",
    "    output_5 = tfk.layers.TimeDistributed( tfk.layers.Dense(2, activation='softmax') ,name='output_3')(model)\n",
    "\n",
    "    model = tfk.models.Model([input1, input2, input3, input4], output_5 )\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T03:17:20.179696Z",
     "iopub.status.busy": "2020-11-18T03:17:20.178490Z",
     "iopub.status.idle": "2020-11-18T04:01:13.899482Z",
     "shell.execute_reply": "2020-11-18T04:01:13.898574Z"
    },
    "papermill": {
     "duration": 2633.751067,
     "end_time": "2020-11-18T04:01:13.899593",
     "exception": false,
     "start_time": "2020-11-18T03:17:20.148526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.fit([X,X_p,X_i,X_m],Y,verbose=1,batch_size=8,epochs=10)\n",
    "# model.save_weights('Weights/BERT.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T04:01:18.982372Z",
     "iopub.status.busy": "2020-11-18T04:01:18.981193Z",
     "iopub.status.idle": "2020-11-18T04:01:19.086362Z",
     "shell.execute_reply": "2020-11-18T04:01:19.087643Z"
    },
    "papermill": {
     "duration": 2.759885,
     "end_time": "2020-11-18T04:01:19.087858",
     "exception": false,
     "start_time": "2020-11-18T04:01:16.327973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights('Weights/BERT.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T04:01:23.377781Z",
     "iopub.status.busy": "2020-11-18T04:01:23.377008Z",
     "iopub.status.idle": "2020-11-18T04:01:30.884923Z",
     "shell.execute_reply": "2020-11-18T04:01:30.884331Z"
    },
    "papermill": {
     "duration": 9.610277,
     "end_time": "2020-11-18T04:01:30.885045",
     "exception": false,
     "start_time": "2020-11-18T04:01:21.274768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model.predict([X_val,X_p_val,X_i_val,X_m_val],verbose=1,batch_size=16)\n",
    "np.savez_compressed('bert-vals', val_tr=Y_val, val_pr=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.sum(Y_val, axis=-1)\n",
    "y_t = np.argmax(Y_val[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[1][0],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[0][1],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "sp,sn,bacc,mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T04:01:44.115390Z",
     "iopub.status.busy": "2020-11-18T04:01:44.114401Z",
     "iopub.status.idle": "2020-11-18T04:01:44.611396Z",
     "shell.execute_reply": "2020-11-18T04:01:44.610429Z"
    },
    "papermill": {
     "duration": 2.624603,
     "end_time": "2020-11-18T04:01:44.611514",
     "exception": false,
     "start_time": "2020-11-18T04:01:41.986911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = np.load('Data/Disordered_Regions_Test_Dataset.npz')\n",
    "test_ids = []\n",
    "with open('Data/SL329_id.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        k = l.split('|')[1].split()[0]\n",
    "        test_ids += [k]\n",
    "te_ids_m = [True if i in test_ids else False for i in tmp['seq_ids']]\n",
    "X_te = np.argmax(tmp['sequences'],axis=-1)[te_ids_m]\n",
    "X_p_te = tmp['pssms'][te_ids_m]\n",
    "Y_te = tmp['regions'][te_ids_m]\n",
    "X_m_te = X_te!=0\n",
    "X_m_te = X_m_te.astype(np.int32)\n",
    "X_i_te = np.repeat(np.arange(1,X_te.shape[1]+1)[None,:], X_te.shape[0], axis=0)\n",
    "X_i_te[X_te==0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T04:01:49.395243Z",
     "iopub.status.busy": "2020-11-18T04:01:49.393925Z",
     "iopub.status.idle": "2020-11-18T04:01:52.122141Z",
     "shell.execute_reply": "2020-11-18T04:01:52.121077Z"
    },
    "papermill": {
     "duration": 5.071089,
     "end_time": "2020-11-18T04:01:52.122265",
     "exception": false,
     "start_time": "2020-11-18T04:01:47.051176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model.predict([X_te,X_p_te,X_i_te,X_m_te],verbose=1,batch_size=16)\n",
    "np.savez_compressed('bert-test', te_tr=Y_te, te_pr=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.098825,
     "end_time": "2020-11-18T04:02:05.284929",
     "exception": false,
     "start_time": "2020-11-18T04:02:03.186104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = np.sum(Y_te, axis=-1)\n",
    "y_t = np.argmax(Y_te[m==1],axis=-1).flatten()\n",
    "y_p = np.argmax(preds[m==1],axis=-1).flatten()\n",
    "print(classification_report(y_t,y_p))\n",
    "t = confusion_matrix(y_t,y_p)\n",
    "print(t,accuracy_score(y_t,y_p))\n",
    "tp = np.array(t[1][1],dtype=np.float64)\n",
    "fp = np.array(t[1][0],dtype=np.float64)\n",
    "tn = np.array(t[0][0],dtype=np.float64)\n",
    "fn = np.array(t[0][1],dtype=np.float64)\n",
    "sp = tp/(tp+fn)\n",
    "sn = tn/(tn+fp)\n",
    "bacc = (sp+sn)/2\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "sp,sn,bacc,mcc,f1_score(y_t,y_p,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 2710.293105,
   "end_time": "2020-11-18T04:02:08.843746",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-18T03:16:58.550641",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
