{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataPath = 'Data/Secondary_Structure_Train_Dataset.npz'\n",
    "testDataPath = 'Data/Secondary_Structure_Test_Dataset.npz'\n",
    "\n",
    "num_aminoAcids = {0:'A', 1:'C', 2:'E', 3:'D', 4:'G', 5:'F', 6:'I', 7:'H', 8:'K', 9:'M', 10:'L',\n",
    "            11:'N', 12:'Q', 13:'P', 14:'S', 15:'R', 16:'T', 17:'W', 18:'V', 19:'Y', 20:'X'}\n",
    "num_ss = {0:'L',1:'B',2:'E',3:'G',4:'I',5:'H',6:'S',7:'T'}\n",
    "aminoAcid_I = {j:i+1 for i,j in num_aminoAcids.items()}\n",
    "aminoAcid_I['<pad>'] = 0\n",
    "aminoAcid_I['<SOS>'] = 0#len(aminoAcid_I)\n",
    "aminoAcid_I['<EOS>'] = 0#len(aminoAcid_I)\n",
    "ss_I = {j:i+1 for i,j in num_ss.items()}\n",
    "ss_I['<pad>'] = 0\n",
    "ss_I['<SOS>'] = len(ss_I)\n",
    "ss_I['<EOS>'] = len(ss_I)\n",
    "\n",
    "tmp = np.load('Data/Secondary_Structure_Motif_Antimotif.npz')\n",
    "motifs = tmp['motifs']\n",
    "antiMotifs = tmp['antimotifs']\n",
    "len(motifs),len(antiMotifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(seq_, pssm_, label, winSize):\n",
    "    winApp = winSize // 2\n",
    "    \n",
    "    input1 = np.zeros((702, winSize))\n",
    "    input2 = np.zeros((702, winSize, 22))\n",
    "    input3 = np.zeros((702, winSize, len(motifs)))\n",
    "    input4 = np.zeros((702, winSize, len(antiMotifs)))\n",
    "    input5 = np.zeros((702, winSize))\n",
    "    input6 = np.zeros((702, 1))\n",
    "    output = np.zeros((702))\n",
    "    \n",
    "    seq = '-' * winApp\n",
    "    pssm = []\n",
    "    seq += 'O'\n",
    "    output[0] = ss_I['<SOS>']\n",
    "    input6[0,0] = 1\n",
    "    input5[0,:] = 1\n",
    "    for j in range(seq_.shape[0]):\n",
    "        if np.sum(seq_[j, :]) == 0:\n",
    "            break\n",
    "        seq += num_aminoAcids[np.argmax(seq_[j, :])]\n",
    "        pssm += [pssm_[j, :]]\n",
    "        output[j+1] = np.argmax(label[j, :]) + 1\n",
    "        input6[j+1,0] = 1\n",
    "        if np.sum(label[j]) == 0:\n",
    "            output[j+1] = 9\n",
    "        input5[j+1,:] = j+2\n",
    "    output[j+2] = ss_I['<EOS>']\n",
    "    input6[j+2,0] = 1\n",
    "    input5[j+2,:] = j+2\n",
    "    seq += 'J'\n",
    "    seq += '-'*winApp\n",
    "    for _ in range(winApp+1):\n",
    "        pssm = [np.zeros((22,))] + pssm\n",
    "        pssm += [np.zeros((22,))]\n",
    "    for j in range(len(seq) - winSize + 1):\n",
    "        a = seq[j : j + winSize]\n",
    "        c = pssm[j : j + winSize]\n",
    "        for t in range(winSize):\n",
    "            if a[t] == 'O':\n",
    "                input1[j, t] = aminoAcid_I['<SOS>']\n",
    "            elif a[t] == 'J':\n",
    "                input1[j, t] = aminoAcid_I['<EOS>']\n",
    "            elif a[t] != '-':\n",
    "                input1[j, t] = aminoAcid_I[a[t]]\n",
    "            input2[j, t] = c[t]\n",
    "            for p,m in enumerate(motifs):\n",
    "                k_ = int(m[3])\n",
    "                if winSize-t > k_:\n",
    "                    if a[t] == m[0] and a[t+k_] == m[1]:\n",
    "                        input3[j, t:t+k_+1, p] += 1.\n",
    "            for p,m in enumerate(antiMotifs):\n",
    "                k_ = int(m[3])\n",
    "                if winSize-t > k_:\n",
    "                    if a[t] == m[0] and a[t+k_] == m[1]:\n",
    "                        input4[j, t:t+k_+1, p] += 1.\n",
    "    return input1, input2, input5, input3, input4, input6, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataGenerator(tfk.utils.Sequence):\n",
    "    def __init__(self, file_path, batch_size=8, win_size=11, seq_len=702, shuffle=False, valData=0):\n",
    "        self.__getData__(file_path)\n",
    "        self.__seq_len__ = seq_len\n",
    "        self.__win_size__ = win_size\n",
    "        self.__batch_size__ = batch_size\n",
    "        self.__shuffle__ = shuffle\n",
    "        self.__valData__ = valData\n",
    "        self.__n_examples__ = self.__sequences.shape[0]\n",
    "        if self.__valData__ == 1:\n",
    "            self.__n_examples__ -= 12000\n",
    "        elif self.__valData__ == 0:\n",
    "            self.__n_examples__ -= 448\n",
    "        self.on_epoch_end()\n",
    "        np.random.seed(42)\n",
    "    def __len__(self):\n",
    "        return self.__n_examples__ // self.__batch_size__\n",
    "    def on_epoch_end(self):\n",
    "        self.__indexes__ = np.arange(self.__n_examples__)\n",
    "        if self.__valData__ == 1:\n",
    "            self.__indexes__ += 12000\n",
    "        if self.__shuffle__:\n",
    "            np.random.shuffle(self.__indexes__)\n",
    "    def __getData__(self, file_path):\n",
    "        data = np.load(file_path)\n",
    "        self.__sequences = data['sequences']\n",
    "        self.__pssms = data['pssms']\n",
    "        self.__secondary_structure = data['secondaryStrucs']\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.__indexes__[index*self.__batch_size__:(index+1)*self.__batch_size__]\n",
    "        X1, X2, X3, X4, X5, X6, y = self.__data_generation(indexes)\n",
    "        return [X1, X2, X3, X4, X5, X6], y\n",
    "    def __data_generation(self, indexes):\n",
    "        x1 = np.empty((self.__batch_size__, self.__seq_len__, self.__win_size__))\n",
    "        x2 = np.empty((self.__batch_size__, self.__seq_len__, self.__win_size__, 22))\n",
    "        x3 = np.empty((self.__batch_size__, self.__seq_len__, self.__win_size__))\n",
    "        x4 = np.empty((self.__batch_size__, self.__seq_len__, self.__win_size__, len(motifs)))\n",
    "        x5 = np.empty((self.__batch_size__, self.__seq_len__, self.__win_size__, len(antiMotifs)))\n",
    "        x6 = np.empty((self.__batch_size__, self.__seq_len__, 1))\n",
    "        y = np.empty((self.__batch_size__, self.__seq_len__))\n",
    "        for k in range(len(indexes)):\n",
    "            ind = indexes[k]\n",
    "            i1,i2,i3,i4,i5,i6,i7 = get_inputs(self.__sequences[ind], self.__pssms[ind],\n",
    "                                              self.__secondary_structure[ind], self.__win_size__)\n",
    "            x1[k,] = i1\n",
    "            x2[k,] = i2\n",
    "            x3[k,] = i3\n",
    "            x4[k,] = i4\n",
    "            x5[k,] = i5\n",
    "            x6[k,] = i6\n",
    "            y[k,] = i7\n",
    "        y = tfk.utils.to_categorical(y,num_classes=12)\n",
    "        return x1, x2, x3, x4, x5, x6, y[:,:,1:9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_list(x):\n",
    "    tmp = list(K.int_shape(x))\n",
    "    tmp[0] = -1\n",
    "    return tmp\n",
    "\n",
    "def selfAttention(V, mask):\n",
    "    units = int(V.shape[2])\n",
    "    Q = tfk.layers.TimeDistributed( tfk.layers.Dense(units, activation=None, use_bias=False))(V)\n",
    "    K_ = tfk.layers.TimeDistributed( tfk.layers.Dense(units, activation=None, use_bias=False))(Q)\n",
    "    SoftAtten = tfk.layers.Dot(axes=-1, normalize=False)([Q, K_])\n",
    "    SoftAtten = tfk.layers.Lambda(lambda inp: inp[0]/K.sqrt(K.cast(shape_list(inp[1])[-1], K.floatx())))([SoftAtten, V])\n",
    "    SoftAtten = tfk.layers.Softmax(axis=-1)(SoftAtten)\n",
    "    SoftAtten = tfk.layers.Multiply()([SoftAtten, mask])\n",
    "    \n",
    "    V = tfk.layers.Permute([2,1])(V)\n",
    "    SA = tfk.layers.Dot(axes=-1, normalize=False)([SoftAtten, V])\n",
    "    return SA,SoftAtten\n",
    "\n",
    "def _getPosEncodingMat(length, dim):\n",
    "    posEnc = np.array([[pos/np.power(10000, 2*(j//2)/dim) for j in range(dim)]\n",
    "                        if pos!=0 else np.zeros(dim) for pos in range(length)], dtype=np.float32)\n",
    "    posEnc[1:, 0::2] = np.sin(posEnc[1:, 0::2])\n",
    "    posEnc[1:, 1::2] = np.cos(posEnc[1:, 1::2])\n",
    "    return posEnc\n",
    "\n",
    "def to_q3(x):\n",
    "    y = []\n",
    "    for i in x:\n",
    "        if i in [0,6,7]:\n",
    "            y += [1]\n",
    "        elif i in [1,2]:\n",
    "            y += [2]\n",
    "        else:\n",
    "            y += [3]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    input1 = tfk.layers.Input(shape=(702,11 ), name='sequence_input')\n",
    "    input2 = tfk.layers.Input(shape=(702,11,22, ), name='pssm_input')\n",
    "    input3 = tfk.layers.Input(shape=(702,11, ), name='pids_input')\n",
    "    input4 = tfk.layers.Input(shape=(702,11,527, ), name='motif_input')\n",
    "    input5 = tfk.layers.Input(shape=(702,11,710, ), name='antimotif_input')\n",
    "    input6 = tfk.layers.Input(shape=(702,1, ), name='mask_input')\n",
    "    \n",
    "    pidsEmbd = tfk.layers.Embedding(input_dim=702, output_dim=100, trainable=False,\n",
    "                                  weights=[_getPosEncodingMat(702, 100)], name='pids_embds')(input3)\n",
    "    emb = tfk.layers.Embedding(input_dim=22, output_dim=100, name='embds')(input1)\n",
    "    seq_embd = tfk.layers.Add(name='seq_embdAdd')([emb, pidsEmbd])\n",
    "    \n",
    "    x1 = tfk.layers.TimeDistributed(tfk.layers.Conv1D(100, 11, strides=1, padding='same', activation='relu'),\n",
    "                                    name='conv1')(seq_embd)\n",
    "    x1 = tfk.layers.TimeDistributed(tfk.layers.GlobalMaxPooling1D())(x1)\n",
    "    x2 = tfk.layers.concatenate([input2, input4, input5], axis=-1, name='con1')\n",
    "    x2 = tfk.layers.TimeDistributed(tfk.layers.Conv1D(100, 11, strides=1, padding='same', activation='relu'),\n",
    "                                    name='conv2')(x2)\n",
    "    x2 = tfk.layers.TimeDistributed(tfk.layers.GlobalMaxPooling1D())(x2)\n",
    "    x1 = tfk.layers.LSTM(units=100, return_sequences=True, name='lstm1')(x1)\n",
    "    \n",
    "    model = tfk.layers.concatenate([x1, x2], axis=-1, name='con2')\n",
    "    model,_ = selfAttention(model, input6)\n",
    "    model = tfk.layers.Bidirectional( tfk.layers.LSTM(units=200, return_sequences=True), name='lstm2')(model)\n",
    "    model = tfk.layers.TimeDistributed( tfk.layers.Dense(200, activation='relu'), name='output1')(model)\n",
    "    output = tfk.layers.TimeDistributed( tfk.layers.Dense(8, activation='softmax') ,name='output')(model)\n",
    "    \n",
    "    model = tfk.models.Model([input1, input2, input3, input4, input5, input6], output)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = dataGenerator(trainDataPath, batch_size=4, seq_len=702)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(train_gen, verbose=1, epochs=10)\n",
    "# model.save_weights('Weights/WB-ALSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('Weights/WB-ALSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = dataGenerator(trainDataPath, batch_size=8, valData=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trues = None\n",
    "preds = None\n",
    "for i in tqdm(range(val_gen.__len__()), total=val_gen.__len__()):\n",
    "    inputs, outputs = val_gen.__getitem__(i)\n",
    "    preds_ = model.predict(inputs)\n",
    "    if trues is None:\n",
    "        trues = outputs\n",
    "        preds = preds_\n",
    "    else:\n",
    "        trues = np.append(trues, outputs, axis=0)\n",
    "        preds = np.append(preds, preds_, axis=0)\n",
    "np.savez_compressed('wb-alstm-vals', val_tr=trues, val_pr=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.sum(trues, axis=-1)\n",
    "y_t = np.argmax(trues[m==1],axis=-1)\n",
    "y_p = np.argmax(preds[m==1],axis=-1)\n",
    "print(classification_report(y_t,y_p))\n",
    "print(accuracy_score(to_q3(y_t),to_q3(y_p)),accuracy_score(y_t,y_p),precision_score(y_t,y_p,average='weighted'),\n",
    "      recall_score(y_t,y_p,average='weighted'), f1_score(y_t,y_p,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = dataGenerator(testDataPath, batch_size=4, valData=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = None\n",
    "preds = None\n",
    "for i in tqdm(range(test_gen.__len__()), total=test_gen.__len__()):\n",
    "    inputs, outputs = test_gen.__getitem__(i)\n",
    "    preds_ = model.predict(inputs)\n",
    "    if trues is None:\n",
    "        trues = outputs\n",
    "        preds = preds_\n",
    "    else:\n",
    "        trues = np.append(trues, outputs, axis=0)\n",
    "        preds = np.append(preds, preds_, axis=0)\n",
    "np.savez_compressed('wb-alstm-test', te_tr=trues, te_pr=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.sum(trues, axis=-1)\n",
    "y_t = np.argmax(trues[m==1],axis=-1)\n",
    "y_p = np.argmax(preds[m==1],axis=-1)\n",
    "print(classification_report(y_t,y_p))\n",
    "print(accuracy_score(to_q3(y_t),to_q3(y_p)),accuracy_score(y_t,y_p),precision_score(y_t,y_p,average='weighted'),\n",
    "      recall_score(y_t,y_p,average='weighted'), f1_score(y_t,y_p,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
