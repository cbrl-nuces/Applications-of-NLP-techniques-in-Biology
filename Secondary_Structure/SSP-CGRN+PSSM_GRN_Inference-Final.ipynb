{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c5adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 15:14:08.747098: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "from sklearn.metrics import *\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc58133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    #strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e371c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_aminoAcids = {0:'A', 1:'C', 2:'E', 3:'D', 4:'G', 5:'F', 6:'I', 7:'H', 8:'K', 9:'M', 10:'L',\n",
    "            11:'N', 12:'Q', 13:'P', 14:'S', 15:'R', 16:'T', 17:'W', 18:'V', 19:'Y', 20:'X'}\n",
    "embedding_keys = {\n",
    "        '<pad>':0,\n",
    "        'A':1,\n",
    "        'C':2,\n",
    "        'D':3,\n",
    "        'E':4,\n",
    "        'F':5,\n",
    "        'G':6,\n",
    "        'H':7,\n",
    "        'I':8,\n",
    "        'K':9,\n",
    "        'L':10,\n",
    "        'M':11,\n",
    "        'N':12,\n",
    "        'P':13,\n",
    "        'Q':14,\n",
    "        'R':15,\n",
    "        'S':16,\n",
    "        'T':17,\n",
    "        'V':18,\n",
    "        'W':19,\n",
    "        'X':20,\n",
    "        'Y':21,\n",
    "        'B':22,\n",
    "        'U':23,\n",
    "        'Z':24,\n",
    "        'O':25,\n",
    "        '<mask>':26}\n",
    "embedding_list = list(embedding_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18cab4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonZeroCCE(tf.keras.losses.Loss):\n",
    "    def __init__(self,Weights=[],smoothing = None):\n",
    "        super().__init__()\n",
    "        if smoothing is not None:\n",
    "            self.cce = tf.keras.losses.CategoricalCrossentropy(reduction='none', label_smoothing=smoothing)\n",
    "        else:\n",
    "            self.cce = tf.keras.losses.CategoricalCrossentropy(reduction='none')\n",
    "        self.weights = np.array(Weights)\n",
    "    def call(self, y_true, y_pred):\n",
    "        if len(self.weights)>0:\n",
    "            loss = self.cce(self.weights*y_true,y_pred)\n",
    "        else:\n",
    "            loss = self.cce(y_true,y_pred)\n",
    "        return tf.math.reduce_sum(loss)/((y_true.shape[0]*y_true.shape[1])-float(tf.math.reduce_sum(tf.cast(tf.equal(tf.math.reduce_sum(y_true,-1),0),tf.int32))))\n",
    "\n",
    "def Accuracy(y_true,y_pred):\n",
    "    y_true = y_true.numpy()\n",
    "    y_pred = y_pred.numpy()\n",
    "\n",
    "    m = np.sum(y_true, axis=-1)\n",
    "    y_t = np.argmax(y_true[m==1],axis=-1)\n",
    "    y_p = np.argmax(y_pred[m==1],axis=-1)\n",
    "    return accuracy_score(y_t,y_p)\n",
    "\n",
    "def to_q3(x):\n",
    "    y = []\n",
    "    for i in x:\n",
    "        if i in [0,6,7]:\n",
    "            y += [1]\n",
    "        elif i in [1,2]:\n",
    "            y += [2]\n",
    "        else:\n",
    "            y += [3]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a8686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 12448/12448 [00:26<00:00, 474.15it/s]\n",
      "2023-04-30 15:14:42.994024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 15:14:43.012101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 15:14:43.012834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 15:14:43.013802: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 15:14:43.014394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 15:14:43.015051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 15:14:43.015555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 15:14:43.460036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 15:14:43.460497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 15:14:43.460840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 15:14:43.461161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10398 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1\n",
      "100%|██████████████████████████████████████| 1992/1992 [00:04<00:00, 422.76it/s]\n",
      "2023-04-30 15:14:54.265408: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2496000000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "#Dataset for SSP\n",
    "num_aminoAcids = {0:'A', 1:'C', 2:'E', 3:'D', 4:'G', 5:'F', 6:'I', 7:'H', 8:'K', 9:'M', 10:'L',\n",
    "            11:'N', 12:'Q', 13:'P', 14:'S', 15:'R', 16:'T', 17:'W', 18:'V', 19:'Y', 20:'X'}\n",
    "num_ss = {0:'L',1:'B',2:'E',3:'G',4:'I',5:'H',6:'S',7:'T'}\n",
    "aminoAcid_I = {j:i+1 for i,j in num_aminoAcids.items()}\n",
    "aminoAcid_I['<pad>'] = 0\n",
    "aminoAcid_I['<S>'] = len(aminoAcid_I)\n",
    "aminoAcid_I['<EOS>'] = len(aminoAcid_I)\n",
    "ss_I = {j:i+1 for i,j in num_ss.items()}\n",
    "ss_I['<pad>'] = 0\n",
    "ss_I['X'] = len(ss_I)\n",
    "ss_I['<S>'] = len(ss_I)\n",
    "ss_I['<EOS>'] = len(ss_I)\n",
    "\n",
    "trainDataPath = './Data/Secondary_Structure_Train_Dataset.npz'\n",
    "testDataPath = './Data/Secondary_Structure_Test_Dataset.npz'\n",
    "\n",
    "tmp = np.load('./Data/Secondary_Structure_Motif_Antimotif.npz')\n",
    "motifs = tmp['motifs']\n",
    "antiMotifs = tmp['antimotifs']\n",
    "len(motifs),len(antiMotifs)\n",
    "def load_data(file_path):\n",
    "    data = np.load(file_path)\n",
    "    sequences = data['sequences']\n",
    "    pssms = data['pssms']\n",
    "    secondary_structure = data['secondaryStrucs']\n",
    "\n",
    "    in1 = np.zeros((sequences.shape[0], 702), dtype=np.int32)\n",
    "    in2 = np.zeros((sequences.shape[0], 702,22), dtype=np.float32)\n",
    "    in3 = np.zeros((sequences.shape[0], 702), dtype=np.int32)\n",
    "    out = np.zeros((sequences.shape[0], 702), dtype=np.int32)\n",
    "    for i in tqdm(range(sequences.shape[0])):\n",
    "        seq = '-'\n",
    "        in1[i,0] = aminoAcid_I['<S>']\n",
    "        in3[i,0] = 1\n",
    "        out[i,0] = ss_I['<S>']\n",
    "        for j in range(sequences.shape[1]):\n",
    "            if np.sum(sequences[i,j,:]) == 0:\n",
    "                in1[i,j+1] = aminoAcid_I['<EOS>']\n",
    "                in3[i,j+1] = j+2\n",
    "                out[i,j+1] = ss_I['<EOS>']\n",
    "                break\n",
    "            in3[i,j+1] = j+2\n",
    "            t = num_aminoAcids[np.argmax(sequences[i,j,:])]\n",
    "            seq += t\n",
    "            in1[i,j+1] = aminoAcid_I[t]\n",
    "            out[i,j+1] = ss_I[num_ss[np.argmax(secondary_structure[i,j,:])]]\n",
    "            if np.sum(secondary_structure[i,j,:]) == 0:\n",
    "                out[i,j+1] = ss_I['X']\n",
    "            in2[i,j+1] = pssms[i,j]\n",
    "    in4 = np.where(in1!=0, 1, 0)[:,:,None]\n",
    "    return in1, in2, in3, in4, out\n",
    "X1, X2, X3, X4, Y = load_data(trainDataPath)\n",
    "X1_val = X1[12000:]\n",
    "X2_val = X2[12000:]\n",
    "X3_val = X3[12000:]\n",
    "X4_val = X4[12000:]\n",
    "Y_val = tf.one_hot(Y[12000:], 9)[:,:,1:]\n",
    "\n",
    "X1 = X1[:12000]\n",
    "X2 = X2[:12000]\n",
    "X3 = X3[:12000]\n",
    "X4 = X4[:12000]\n",
    "Y = tf.one_hot(Y[:12000], 9)[:,:,1:]\n",
    "\n",
    "X1_te, X2_te, X3_te, X4_te, Y_te = load_data(testDataPath)\n",
    "Y_te = tf.one_hot(Y_te, 9)[:,:,1:]\n",
    "\n",
    "X1_temp = []\n",
    "for seq in X1:\n",
    "    end = np.where(seq==23)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(seq)\n",
    "    else:\n",
    "        end = end[0]\n",
    "    X1_temp.append([embedding_keys[num_aminoAcids[seq[idx]-1]] for idx in range(1,end)])\n",
    "    X1_temp[-1].extend([0]*(2000-len(X1_temp[-1])))\n",
    "    X1_temp[-1] = np.array(X1_temp[-1])\n",
    "X1_temp = np.array(X1_temp)\n",
    "\n",
    "\n",
    "X1_val_temp = []\n",
    "for seq in X1_val:\n",
    "    end = np.where(seq==23)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(seq)\n",
    "    else:\n",
    "        end = end[0]\n",
    "    X1_val_temp.append([embedding_keys[num_aminoAcids[seq[idx]-1]] for idx in range(1,end)])\n",
    "    X1_val_temp[-1].extend([0]*(2000-len(X1_val_temp[-1])))\n",
    "    X1_val_temp[-1] = np.array(X1_val_temp[-1])\n",
    "X1_val_temp = np.array(X1_val_temp)\n",
    "\n",
    "X1_te_temp = []\n",
    "i=0\n",
    "for seq in X1_te:\n",
    "    end = np.where(seq==23)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(seq)-1\n",
    "    else:\n",
    "        end = end[0]\n",
    "    X1_te_temp.append([embedding_keys[num_aminoAcids[seq[idx]-1]] for idx in range(1,end)])\n",
    "    X1_te_temp[-1].extend([0]*(2000-len(X1_te_temp[-1])))\n",
    "    X1_te_temp[-1] = np.array(X1_te_temp[-1])\n",
    "    i+=1\n",
    "X1_te_temp = np.array(X1_te_temp)\n",
    "\n",
    "X1_temp_oneHot = np.array(tf.one_hot(X1_temp,len(embedding_keys))[:,:,1:])\n",
    "X1_val_temp_oneHot = np.array(tf.one_hot(X1_val_temp,len(embedding_keys))[:,:,1:])\n",
    "X1_te_temp_oneHot = np.array(tf.one_hot(X1_te_temp,len(embedding_keys))[:,:,1:])\n",
    "\n",
    "X4 = X4[:,1:701,:]\n",
    "X4_val = X4_val[:,1:701,:]\n",
    "X4_te = X4_te[:,1:701,:]\n",
    "\n",
    "X2 = X2[:,1:701,:]\n",
    "X2_val = X2_val[:,1:701,:]\n",
    "X2_te = X2_te[:,1:701,:]\n",
    "\n",
    "Y = Y[:,1:701,:]\n",
    "Y_val = Y_val[:,1:701,:]\n",
    "Y_te = Y_te[:,1:701,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c43d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embeddingLoader(tfk.utils.Sequence):\n",
    "    def __init__(self,path,pssms, masks,Y_oneHot,batch_size=30,shuffle=True):\n",
    "        self.path = path\n",
    "        self.pssms = pssms\n",
    "        self.masks = masks\n",
    "        self.Y_oneHot = copy.deepcopy(np.array(Y_oneHot))\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.length = len(Y_oneHot)\n",
    "        self.indices = np.arange(0,self.length)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def generate_batches(self):\n",
    "        self.Y_oneHot_ = self.Y_oneHot[self.indices]\n",
    "        self.pssms_ = self.pssms[self.indices]\n",
    "        self.masks_ = self.masks[self.indices]\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        self.generate_batches()\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        token_representations = []\n",
    "        for idx in self.indices[index*self.batch_size:(index+1)*self.batch_size]:\n",
    "            token_representations.append(np.load(self.path+str(idx).zfill(6)+'.npy')[0])\n",
    "        return ([\n",
    "                tf.convert_to_tensor(np.array(token_representations)),\n",
    "                self.masks_[index*self.batch_size:(index+1)*self.batch_size],\n",
    "                self.pssms_[index*self.batch_size:(index+1)*self.batch_size]\n",
    "                ],\n",
    "                self.Y_oneHot_[index*self.batch_size:(index+1)*self.batch_size]\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        if self.length%self.batch_size!=0:\n",
    "            return 1+(self.length//self.batch_size)\n",
    "        return self.length//self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a15c9ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence_input (InputLayer)    [(None, 700, 300)]   0           []                               \n",
      "                                                                                                  \n",
      " mask (InputLayer)              [(None, 700, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 700, 300)     0           ['sequence_input[0][0]',         \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " pssm (InputLayer)              [(None, 700, 22)]    0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 700, 322)     0           ['multiply[0][0]',               \n",
      "                                                                  'pssm[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru1 (Bidirectional)         (None, 700, 300)     426600      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 700, 300)     0           ['bigru1[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru2 (Bidirectional)         (None, 700, 300)     406800      ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 700, 300)     0           ['bigru2[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output1 (TimeDistributed)      (None, 700, 500)     150500      ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 700, 500)     0           ['output1[0][0]',                \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output2 (TimeDistributed)      (None, 700, 500)     250500      ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " output (TimeDistributed)       (None, 700, 8)       4008        ['output2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,238,408\n",
      "Trainable params: 1,238,408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    input1_ = tfk.layers.Input(shape=(700,300, ), name='sequence_input')\n",
    "    input2_ = tfk.layers.Input(shape=(700,1, ), name='mask')\n",
    "    input3_ = tfk.layers.Input(shape=(700,22, ), name='pssm')\n",
    "    \n",
    "    x = tfk.layers.Multiply()([input1_, input2_])\n",
    "    x = tfk.layers.concatenate([x, input3_], axis=-1)\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru2')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output2')(x)\n",
    "    output_ = tfk.layers.TimeDistributed(tfk.layers.Dense(8, activation='softmax') ,name='output')(x)\n",
    "    \n",
    "    conv_model = tfk.models.Model([input1_, input2_, input3_], output_)\n",
    "    conv_model.compile(loss=NonZeroCCE(), metrics=[Accuracy], optimizer='adam', run_eagerly = True)\n",
    "    conv_model.summary()\n",
    "conv_model.load_weights(\"./Weights/conv_pssm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e79b03a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************Conv ONLY*******************************************\n",
      "\n",
      "\n",
      "*******************************************VALIDATION*******************************************\n",
      " 1/15 [=>............................] - ETA: 7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 15:25:04.758635: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 135ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70      8216\n",
      "           1       0.31      0.05      0.09       833\n",
      "           2       0.82      0.87      0.84     19387\n",
      "           3       0.40      0.25      0.31      3100\n",
      "           4       0.42      0.10      0.16       551\n",
      "           5       0.85      0.89      0.87     33679\n",
      "           6       0.49      0.47      0.48      8082\n",
      "           7       0.56      0.51      0.53      9997\n",
      "\n",
      "    accuracy                           0.75     83845\n",
      "   macro avg       0.56      0.48      0.50     83845\n",
      "weighted avg       0.73      0.75      0.74     83845\n",
      "\n",
      "0.828254517263999 0.7463176098753652 0.731377393381401 0.7463176098753652 0.7360303510987957 0.8281389416956056\n",
      "\n",
      "\n",
      "*******************************************Test*******************************************\n",
      "67/67 [==============================] - 9s 136ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.72     50478\n",
      "           1       0.33      0.06      0.10      4782\n",
      "           2       0.79      0.87      0.83     91469\n",
      "           3       0.43      0.24      0.31     16734\n",
      "           4       0.60      0.19      0.28      2537\n",
      "           5       0.84      0.89      0.86    161303\n",
      "           6       0.46      0.47      0.47     38765\n",
      "           7       0.55      0.51      0.53     48774\n",
      "\n",
      "    accuracy                           0.74    414842\n",
      "   macro avg       0.59      0.49      0.51    414842\n",
      "weighted avg       0.72      0.74      0.73    414842\n",
      "\n",
      "0.8230217769656881 0.7391633441165553 0.7244279307102875 0.7391633441165553 0.7282869988306275 0.8226713596327812\n"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************Conv ONLY*******************************************\")\n",
    "print()\n",
    "print()\n",
    "val_loader = embeddingLoader(\"./Data/Embeddings/Conv/val/\",X2_val,X4_val,Y_val,30,False)\n",
    "print(\"*******************************************VALIDATION*******************************************\")\n",
    "preds = conv_model.predict(val_loader, verbose=1)\n",
    "\n",
    "m = np.sum(Y_val, axis=-1)\n",
    "y_t = np.argmax(Y_val[m==1],axis=-1)\n",
    "y_p = np.argmax(preds[m==1],axis=-1)\n",
    "print(classification_report(y_t,y_p,zero_division=0))\n",
    "print(accuracy_score(to_q3(y_t),to_q3(y_p)),accuracy_score(y_t,y_p),precision_score(y_t,y_p,average='weighted',zero_division=0),\n",
    "      recall_score(y_t,y_p,average='weighted',zero_division=0), f1_score(y_t,y_p,average='weighted',zero_division=0),f1_score(to_q3(y_t),to_q3(y_p),average='weighted',zero_division=0))\n",
    "\n",
    "test_loader = embeddingLoader(\"./Data/Embeddings/Conv/test/\",X2_te, X4_te,Y_te,30,False)\n",
    "print()\n",
    "print()\n",
    "print(\"*******************************************Test*******************************************\")\n",
    "preds = conv_model.predict(test_loader, verbose=1)\n",
    "m = np.sum(Y_te, axis=-1)\n",
    "y_t = np.argmax(Y_te[m==1],axis=-1)\n",
    "y_p = np.argmax(preds[m==1],axis=-1)\n",
    "print(classification_report(y_t,y_p,zero_division=0))\n",
    "print(accuracy_score(to_q3(y_t),to_q3(y_p)),accuracy_score(y_t,y_p),precision_score(y_t,y_p,average='weighted',zero_division=0),\n",
    "      recall_score(y_t,y_p,average='weighted',zero_division=0), f1_score(y_t,y_p,average='weighted',zero_division=0),f1_score(to_q3(y_t),to_q3(y_p),average='weighted',zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32f588d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence_input (InputLayer)    [(None, 700, 300)]   0           []                               \n",
      "                                                                                                  \n",
      " mask (InputLayer)              [(None, 700, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 700, 300)     0           ['sequence_input[0][0]',         \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " pssm (InputLayer)              [(None, 700, 22)]    0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 700, 322)     0           ['multiply_4[0][0]',             \n",
      "                                                                  'pssm[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru1 (Bidirectional)         (None, 700, 300)     426600      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 700, 300)     0           ['bigru1[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru2 (Bidirectional)         (None, 700, 300)     406800      ['multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 700, 300)     0           ['bigru2[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output1 (TimeDistributed)      (None, 700, 500)     150500      ['multiply_6[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 700, 500)     0           ['output1[0][0]',                \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output2 (TimeDistributed)      (None, 700, 500)     250500      ['multiply_7[0][0]']             \n",
      "                                                                                                  \n",
      " output (TimeDistributed)       (None, 700, 8)       4008        ['output2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,238,408\n",
      "Trainable params: 1,238,408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    input1_ = tfk.layers.Input(shape=(700,300, ), name='sequence_input')\n",
    "    input2_ = tfk.layers.Input(shape=(700,1, ), name='mask')\n",
    "    input3_ = tfk.layers.Input(shape=(700,22, ), name='pssm')\n",
    "    \n",
    "    x = tfk.layers.Multiply()([input1_, input2_])\n",
    "    x = tfk.layers.concatenate([x, input3_], axis=-1)\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru2')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output2')(x)\n",
    "    output_ = tfk.layers.TimeDistributed(tfk.layers.Dense(8, activation='softmax') ,name='output')(x)\n",
    "\n",
    "    gru_model = tfk.models.Model([input1_, input2_, input3_], output_)\n",
    "    gru_model.compile(loss=NonZeroCCE(), metrics=[Accuracy], optimizer='adam', run_eagerly = True)\n",
    "    gru_model.summary()\n",
    "gru_model.load_weights(\"./Weights/gru_pssm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aca45285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************GRU ONLY*******************************************\n",
      "\n",
      "\n",
      "*******************************************VALIDATION*******************************************\n",
      "15/15 [==============================] - 2s 136ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72      8216\n",
      "           1       0.39      0.03      0.05       833\n",
      "           2       0.78      0.90      0.84     19387\n",
      "           3       0.41      0.24      0.30      3100\n",
      "           4       0.50      0.09      0.15       551\n",
      "           5       0.83      0.93      0.87     33679\n",
      "           6       0.55      0.40      0.46      8082\n",
      "           7       0.60      0.48      0.53      9997\n",
      "\n",
      "    accuracy                           0.76     83845\n",
      "   macro avg       0.60      0.47      0.49     83845\n",
      "weighted avg       0.73      0.76      0.74     83845\n",
      "\n",
      "0.8299123382431869 0.755835172043652 0.732023508999256 0.755835172043652 0.7363372829547511 0.8267525713236787\n",
      "\n",
      "\n",
      "*******************************************Test*******************************************\n",
      "67/67 [==============================] - 9s 136ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74     50478\n",
      "           1       0.50      0.03      0.06      4782\n",
      "           2       0.76      0.91      0.83     91469\n",
      "           3       0.46      0.23      0.31     16734\n",
      "           4       0.67      0.16      0.26      2537\n",
      "           5       0.81      0.92      0.86    161303\n",
      "           6       0.52      0.38      0.44     38765\n",
      "           7       0.59      0.48      0.53     48774\n",
      "\n",
      "    accuracy                           0.75    414842\n",
      "   macro avg       0.64      0.48      0.50    414842\n",
      "weighted avg       0.73      0.75      0.73    414842\n",
      "\n",
      "0.8236051315922689 0.747405036134239 0.7260688329904169 0.747405036134239 0.7271689095964685 0.8206063515192554\n"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************GRU ONLY*******************************************\")\n",
    "print()\n",
    "print()\n",
    "val_loader = embeddingLoader(\"./Data/Embeddings/GRU/val/\",X2_val,X4_val,Y_val,30,False)\n",
    "print(\"*******************************************VALIDATION*******************************************\")\n",
    "preds = gru_model.predict(val_loader, verbose=1)\n",
    "\n",
    "m = np.sum(Y_val, axis=-1)\n",
    "y_t = np.argmax(Y_val[m==1],axis=-1)\n",
    "y_p = np.argmax(preds[m==1],axis=-1)\n",
    "print(classification_report(y_t,y_p,zero_division=0))\n",
    "print(accuracy_score(to_q3(y_t),to_q3(y_p)),accuracy_score(y_t,y_p),precision_score(y_t,y_p,average='weighted',zero_division=0),\n",
    "      recall_score(y_t,y_p,average='weighted',zero_division=0), f1_score(y_t,y_p,average='weighted',zero_division=0),f1_score(to_q3(y_t),to_q3(y_p),average='weighted',zero_division=0))\n",
    "\n",
    "test_loader = embeddingLoader(\"./Data/Embeddings/GRU/test/\",X2_te, X4_te,Y_te,30,False)\n",
    "print()\n",
    "print()\n",
    "print(\"*******************************************Test*******************************************\")\n",
    "preds = gru_model.predict(test_loader, verbose=1)\n",
    "m = np.sum(Y_te, axis=-1)\n",
    "y_t = np.argmax(Y_te[m==1],axis=-1)\n",
    "y_p = np.argmax(preds[m==1],axis=-1)\n",
    "print(classification_report(y_t,y_p,zero_division=0))\n",
    "print(accuracy_score(to_q3(y_t),to_q3(y_p)),accuracy_score(y_t,y_p),precision_score(y_t,y_p,average='weighted',zero_division=0),\n",
    "      recall_score(y_t,y_p,average='weighted',zero_division=0), f1_score(y_t,y_p,average='weighted',zero_division=0),f1_score(to_q3(y_t),to_q3(y_p),average='weighted',zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418072d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence_input (InputLayer)    [(None, 700, 600)]   0           []                               \n",
      "                                                                                                  \n",
      " mask (InputLayer)              [(None, 700, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)          (None, 700, 600)     0           ['sequence_input[0][0]',         \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " pssm (InputLayer)              [(None, 700, 22)]    0           []                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 700, 622)     0           ['multiply_8[0][0]',             \n",
      "                                                                  'pssm[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru1 (Bidirectional)         (None, 700, 300)     696600      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_9 (Multiply)          (None, 700, 300)     0           ['bigru1[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " bigru2 (Bidirectional)         (None, 700, 300)     406800      ['multiply_9[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_10 (Multiply)         (None, 700, 300)     0           ['bigru2[0][0]',                 \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output1 (TimeDistributed)      (None, 700, 500)     150500      ['multiply_10[0][0]']            \n",
      "                                                                                                  \n",
      " multiply_11 (Multiply)         (None, 700, 500)     0           ['output1[0][0]',                \n",
      "                                                                  'mask[0][0]']                   \n",
      "                                                                                                  \n",
      " output2 (TimeDistributed)      (None, 700, 500)     250500      ['multiply_11[0][0]']            \n",
      "                                                                                                  \n",
      " output (TimeDistributed)       (None, 700, 8)       4008        ['output2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,508,408\n",
      "Trainable params: 1,508,408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    input1_ = tfk.layers.Input(shape=(700,600, ), name='sequence_input')\n",
    "    input2_ = tfk.layers.Input(shape=(700,1, ), name='mask')\n",
    "    input3_ = tfk.layers.Input(shape=(700,22, ), name='pssm')\n",
    "    \n",
    "    x = tfk.layers.Multiply()([input1_, input2_])\n",
    "    x = tfk.layers.concatenate([x, input3_], axis=-1)\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.Bidirectional(tfk.layers.GRU(units=150, return_sequences=True), name='bigru2')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output1')(x)\n",
    "    x = tfk.layers.Multiply()([x, input2_])\n",
    "    x = tfk.layers.TimeDistributed(tfk.layers.Dense(500, activation='relu'), name='output2')(x)\n",
    "    output_ = tfk.layers.TimeDistributed(tfk.layers.Dense(8, activation='softmax') ,name='output')(x)\n",
    "\n",
    "    conv_GRU_model = tfk.models.Model([input1_, input2_, input3_], output_)\n",
    "    conv_GRU_model.compile(loss=NonZeroCCE(), metrics=[Accuracy], optimizer='adam', run_eagerly = True)\n",
    "    conv_GRU_model.summary()\n",
    "conv_GRU_model.load_weights(\"./Weights/conv_gru_pssm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8420eff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************Conv_GRU ONLY*******************************************\n",
      "\n",
      "\n",
      "*******************************************VALIDATION*******************************************\n",
      "15/15 [==============================] - 3s 183ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71      8216\n",
      "           1       0.41      0.04      0.08       833\n",
      "           2       0.85      0.83      0.84     19387\n",
      "           3       0.39      0.24      0.30      3100\n",
      "           4       0.42      0.11      0.17       551\n",
      "           5       0.80      0.94      0.86     33679\n",
      "           6       0.56      0.37      0.45      8082\n",
      "           7       0.54      0.54      0.54      9997\n",
      "\n",
      "    accuracy                           0.75     83845\n",
      "   macro avg       0.59      0.47      0.49     83845\n",
      "weighted avg       0.73      0.75      0.73     83845\n",
      "\n",
      "0.8280994692587512 0.7492038881269009 0.7303223747213653 0.7492038881269009 0.7325560431730684 0.8254479639942232\n",
      "\n",
      "\n",
      "*******************************************Test*******************************************\n",
      "67/67 [==============================] - 13s 186ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74     50478\n",
      "           1       0.41      0.04      0.08      4782\n",
      "           2       0.83      0.84      0.83     91469\n",
      "           3       0.42      0.24      0.30     16734\n",
      "           4       0.56      0.20      0.29      2537\n",
      "           5       0.79      0.94      0.86    161303\n",
      "           6       0.54      0.37      0.43     38765\n",
      "           7       0.54      0.55      0.54     48774\n",
      "\n",
      "    accuracy                           0.74    414842\n",
      "   macro avg       0.61      0.48      0.51    414842\n",
      "weighted avg       0.73      0.74      0.73    414842\n",
      "\n",
      "0.8236147738175016 0.7437024216448672 0.7255850779512723 0.7437024216448672 0.7269354055626455 0.8211205809667153\n"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************Conv_GRU ONLY*******************************************\")\n",
    "print()\n",
    "print()\n",
    "val_loader = embeddingLoader(\"./Data/Embeddings/Conv_GRU/val/\",X2_val,X4_val,Y_val,30,False)\n",
    "print(\"*******************************************VALIDATION*******************************************\")\n",
    "preds = conv_GRU_model.predict(val_loader, verbose=1)\n",
    "\n",
    "m = np.sum(Y_val, axis=-1)\n",
    "y_t = np.argmax(Y_val[m==1],axis=-1)\n",
    "y_p = np.argmax(preds[m==1],axis=-1)\n",
    "print(classification_report(y_t,y_p,zero_division=0))\n",
    "print(accuracy_score(to_q3(y_t),to_q3(y_p)),accuracy_score(y_t,y_p),precision_score(y_t,y_p,average='weighted',zero_division=0),\n",
    "      recall_score(y_t,y_p,average='weighted',zero_division=0), f1_score(y_t,y_p,average='weighted',zero_division=0),f1_score(to_q3(y_t),to_q3(y_p),average='weighted',zero_division=0))\n",
    "\n",
    "test_loader = embeddingLoader(\"./Data/Embeddings/Conv_GRU/test/\",X2_te, X4_te,Y_te,30,False)\n",
    "print()\n",
    "print()\n",
    "print(\"*******************************************Test*******************************************\")\n",
    "preds = conv_GRU_model.predict(test_loader, verbose=1)\n",
    "m = np.sum(Y_te, axis=-1)\n",
    "y_t = np.argmax(Y_te[m==1],axis=-1)\n",
    "y_p = np.argmax(preds[m==1],axis=-1)\n",
    "print(classification_report(y_t,y_p,zero_division=0))\n",
    "print(accuracy_score(to_q3(y_t),to_q3(y_p)),accuracy_score(y_t,y_p),precision_score(y_t,y_p,average='weighted',zero_division=0),\n",
    "      recall_score(y_t,y_p,average='weighted',zero_division=0), f1_score(y_t,y_p,average='weighted',zero_division=0),f1_score(to_q3(y_t),to_q3(y_p),average='weighted',zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a7704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
